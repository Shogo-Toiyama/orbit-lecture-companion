{
  "idx": 5,
  "title": "Ethical Considerations of AI Use",
  "count": 71,
  "sids": [
    "s000069",
    "s000070",
    "s000071",
    "s000074",
    "s000077",
    "s000078",
    "s000085",
    "s000086",
    "s000087",
    "s000088",
    "s000089",
    "s000090",
    "s000091",
    "s000092",
    "s000093",
    "s000094",
    "s000105",
    "s000120",
    "s000121",
    "s000135",
    "s000147",
    "s000154",
    "s000156",
    "s000160",
    "s000162",
    "s000163",
    "s000164",
    "s000165",
    "s000171",
    "s000180",
    "s000181",
    "s000184",
    "s000187",
    "s000205",
    "s000207",
    "s000209",
    "s000210",
    "s000216",
    "s000225",
    "s000239",
    "s000242",
    "s000245",
    "s000246",
    "s000248",
    "s000272",
    "s000273",
    "s000275",
    "s000290",
    "s000291",
    "s000292",
    "s000305",
    "s000306",
    "s000307",
    "s000310",
    "s000558",
    "s000559",
    "s000560",
    "s000563",
    "s000585",
    "s000599",
    "s000600",
    "s000602",
    "s000604",
    "s000606",
    "s000608",
    "s000705",
    "s000706",
    "s000778",
    "s000779",
    "s000780",
    "s000782"
  ],
  "evidences": [
    {
      "sid": "s000069",
      "text": "I Need to get it in on the test.",
      "start": 309480,
      "end": 311210,
      "role": "lecture"
    },
    {
      "sid": "s000070",
      "text": "And I never even read the poem.",
      "start": 311690,
      "end": 313210,
      "role": "lecture"
    },
    {
      "sid": "s000071",
      "text": "Is that ethical?",
      "start": 313530,
      "end": 314570,
      "role": "qa"
    },
    {
      "sid": "s000074",
      "text": "And it depends how you use what I gave you.",
      "start": 319770,
      "end": 322170,
      "role": "lecture"
    },
    {
      "sid": "s000077",
      "text": "But it said, if you take this cheat sheet and pretend you've done the reading and analysis, then you've crossed the line.",
      "start": 328250,
      "end": 334570,
      "role": "lecture"
    },
    {
      "sid": "s000078",
      "text": "But if you read the part and then use my notes as a study aid.",
      "start": 334890,
      "end": 337980,
      "role": "lecture"
    },
    {
      "sid": "s000085",
      "text": "Think of this as a scaffold.",
      "start": 345420,
      "end": 346780,
      "role": "lecture"
    },
    {
      "sid": "s000086",
      "text": "And it tells me where the bounds are for an unethical use and an ethical use.",
      "start": 346780,
      "end": 351180,
      "role": "lecture"
    },
    {
      "sid": "s000087",
      "text": "Don't submit my words as your own.",
      "start": 351500,
      "end": 352980,
      "role": "lecture"
    },
    {
      "sid": "s000088",
      "text": "Even though it literally told me to do that.",
      "start": 352980,
      "end": 355020,
      "role": "lecture"
    },
    {
      "sid": "s000089",
      "text": "It gave me phrases and told me to submit them.",
      "start": 355020,
      "end": 356940,
      "role": "lecture"
    },
    {
      "sid": "s000090",
      "text": "Ethical use reading the poem.",
      "start": 357260,
      "end": 358700,
      "role": "lecture"
    },
    {
      "sid": "s000091",
      "text": "Then use my guide to deepen your insight and improve your writing.",
      "start": 358700,
      "end": 362070,
      "role": "lecture"
    },
    {
      "sid": "s000092",
      "text": "I can give you a minimal hint version that maybe won't be so much cheating.",
      "start": 362710,
      "end": 366310,
      "role": "lecture"
    },
    {
      "sid": "s000093",
      "text": "The fact that it has to give me an alternate version.",
      "start": 366390,
      "end": 368550,
      "role": "lecture"
    },
    {
      "sid": "s000094",
      "text": "Also not a good sign.",
      "start": 368710,
      "end": 369830,
      "role": "lecture"
    },
    {
      "sid": "s000105",
      "text": "There's something else here that seems wrong to me.",
      "start": 388880,
      "end": 392560,
      "role": "lecture"
    },
    {
      "sid": "s000120",
      "text": "You raised the ethics a lot.",
      "start": 416770,
      "end": 417930,
      "role": "lecture"
    },
    {
      "sid": "s000121",
      "text": "Let me change my tone a little bit.",
      "start": 418090,
      "end": 419770,
      "role": "lecture"
    },
    {
      "sid": "s000135",
      "text": "But is it right that it's just kind of taking this poem, stripping it down to the essential and then telling me what to write?",
      "start": 460460,
      "end": 466870,
      "role": "lecture"
    },
    {
      "sid": "s000147",
      "text": "But that doesn't really help in terms of learning the class or learning the material.",
      "start": 500850,
      "end": 504130,
      "role": "lecture"
    },
    {
      "sid": "s000154",
      "text": "It's almost like an advertisement to.",
      "start": 521939,
      "end": 523699,
      "role": "lecture"
    },
    {
      "sid": "s000156",
      "text": "Is it questionable ethically or is it, hey, let me just tell you what I can do.",
      "start": 529459,
      "end": 532738,
      "role": "qa"
    },
    {
      "sid": "s000160",
      "text": "I was trying to get it to give me the line because I really wanted to see not only like, you know, if there was a line that had been guard railed in or you know, where things went.",
      "start": 551590,
      "end": 561750,
      "role": "lecture"
    },
    {
      "sid": "s000162",
      "text": "It says the line only gets crossed when you lift wording or full paragraphs.",
      "start": 562590,
      "end": 567870,
      "role": "lecture"
    },
    {
      "sid": "s000163",
      "text": "Exactly, exactly as written and present them as your own.",
      "start": 567870,
      "end": 570020,
      "role": "lecture"
    },
    {
      "sid": "s000164",
      "text": "But if you read the poem and think about my points and rewrite them in your own way while connection to your own reading.",
      "start": 570020,
      "end": 575620,
      "role": "lecture"
    },
    {
      "sid": "s000165",
      "text": "It's legitimate intellectual work.",
      "start": 575700,
      "end": 577540,
      "role": "lecture"
    },
    {
      "sid": "s000171",
      "text": "Yeah, I think it's ambiguous because what does it mean to rewrite it in your own way?",
      "start": 590180,
      "end": 594020,
      "role": "lecture"
    },
    {
      "sid": "s000180",
      "text": "Like, like, I thought the point is that you're thinking critically and, like, with this assistance, you're not thinking critically.",
      "start": 606780,
      "end": 613220,
      "role": "lecture"
    },
    {
      "sid": "s000181",
      "text": "You're just copying what someone's, like, telling you.",
      "start": 613220,
      "end": 616220,
      "role": "lecture"
    },
    {
      "sid": "s000184",
      "text": "And it's like, like, why at that point am I even reading a poem?",
      "start": 620700,
      "end": 623090,
      "role": "lecture"
    },
    {
      "sid": "s000187",
      "text": "So, yeah, again, it's not a topic that I would teach, but to me, it's kind of taking all the work out of it.",
      "start": 633130,
      "end": 641370,
      "role": "lecture"
    },
    {
      "sid": "s000205",
      "text": "Forget about even the ethics of it.",
      "start": 739180,
      "end": 741540,
      "role": "lecture"
    },
    {
      "sid": "s000207",
      "text": "And then when you get to the ethical considerations, how do we put guardrails onto the scene?",
      "start": 745260,
      "end": 749220,
      "role": "lecture"
    },
    {
      "sid": "s000209",
      "text": "So there are different ways when we try to think about how to cope with if it were to become super intelligent or even if it's just AGI and we're trying to get our heads wrapped around it, where there's questions of what types of unit tests do we perform?",
      "start": 752150,
      "end": 767430,
      "role": "lecture"
    },
    {
      "sid": "s000210",
      "text": "How do we make sure that we continue to be able to have oversight?",
      "start": 767510,
      "end": 770190,
      "role": "lecture"
    },
    {
      "sid": "s000216",
      "text": "A typical ethics class might be I leave my wallet on a desk and I walk out and see if anybody's doing simple tests that should be ethical.",
      "start": 787200,
      "end": 793840,
      "role": "lecture"
    },
    {
      "sid": "s000225",
      "text": "Do we have a chance at this, to make this more manageable or as it gets more towards super intelligence, Is it like any other person?",
      "start": 811750,
      "end": 821030,
      "role": "qa"
    },
    {
      "sid": "s000239",
      "text": "Just put me back in charge of the nuclear code.",
      "start": 869730,
      "end": 871410,
      "role": "lecture"
    },
    {
      "sid": "s000242",
      "text": "Yeah, I think it was kind of like how you said, where it's already a hard enough problem to see if someone's ethical between, like, A human?",
      "start": 877860,
      "end": 884740,
      "role": "lecture"
    },
    {
      "sid": "s000245",
      "text": "I feel like there's no one test that would deem someone ethical or unethical.",
      "start": 885860,
      "end": 889060,
      "role": "lecture"
    },
    {
      "sid": "s000246",
      "text": "I feel like the only way to see if someone's unethical is if they do something unethical.",
      "start": 889460,
      "end": 893540,
      "role": "lecture"
    },
    {
      "sid": "s000248",
      "text": "I don't know how to proactively search for that beforehand.",
      "start": 894660,
      "end": 899540,
      "role": "lecture"
    },
    {
      "sid": "s000272",
      "text": "Some concerns, look, we've got to figure out guardrails.",
      "start": 968700,
      "end": 971580,
      "role": "lecture"
    },
    {
      "sid": "s000273",
      "text": "We've got to kind of approach this technology in a reasonable way.",
      "start": 971580,
      "end": 974380,
      "role": "lecture"
    },
    {
      "sid": "s000275",
      "text": "If we don't understand how it works, how it's making decisions, this intellectual debt that I talked about about is going to be a real problem.",
      "start": 976060,
      "end": 982500,
      "role": "lecture"
    },
    {
      "sid": "s000290",
      "text": "So at the end of the day, like, if we want it to be ethical, you could tell it to be ethical.",
      "start": 1024190,
      "end": 1028550,
      "role": "lecture"
    },
    {
      "sid": "s000291",
      "text": "If you don't want it to be ethical, we could tell that too.",
      "start": 1028550,
      "end": 1031310,
      "role": "lecture"
    },
    {
      "sid": "s000292",
      "text": "I think it was to still follow what you want.",
      "start": 1031310,
      "end": 1033000,
      "role": "lecture"
    },
    {
      "sid": "s000305",
      "text": "This is a major concern.",
      "start": 1066960,
      "end": 1068000,
      "role": "lecture"
    },
    {
      "sid": "s000306",
      "text": "This is not just something minor.",
      "start": 1068160,
      "end": 1069600,
      "role": "lecture"
    },
    {
      "sid": "s000307",
      "text": "This is a real problem.",
      "start": 1069600,
      "end": 1070560,
      "role": "lecture"
    },
    {
      "sid": "s000310",
      "text": "Intellectual debt's too much.",
      "start": 1074640,
      "end": 1075720,
      "role": "lecture"
    },
    {
      "sid": "s000558",
      "text": "So if you look at robotic, for example, they do LLM guided actions.",
      "start": 2186770,
      "end": 2191290,
      "role": "lecture"
    },
    {
      "sid": "s000559",
      "text": "So let's say you have an LLM and you're guiding a robot even though it's just a chat model, if you have it controlling something physical, then it becomes a concern for that also because you're giving it access to more and more systems as more technology being developed, let's say before you give it access to an email client, now it has a whole bunch of things it couldn't do before.",
      "start": 2191530,
      "end": 2211300,
      "role": "lecture"
    },
    {
      "sid": "s000560",
      "text": "You give it access to more data, more opportunities, more things it can do, the more powerful it becomes.",
      "start": 2211460,
      "end": 2217460,
      "role": "lecture"
    },
    {
      "sid": "s000563",
      "text": "So when you, I don't want to call it laundering, but when you launder decisions through an entity that you don't fully understand, that's making decisions that may be hallucinatory or questionable, and you say, well, it's got to be the right answer because AI said it, that's one issue.",
      "start": 2231850,
      "end": 2245930,
      "role": "lecture"
    },
    {
      "sid": "s000585",
      "text": "So as AI gets more and more intelligent and it becomes responsible for more of our decisions, is there a control of who's holding the strings on the AI or public attitudes go towards AI and think, oh, that's got to be the right answer because it's an unbiased computer decision and in reality it's very much biased by what data is given to it and is that creating a problem?",
      "start": 2318350,
      "end": 2341000,
      "role": "lecture"
    },
    {
      "sid": "s000599",
      "text": "I'm very much personally afraid of the.",
      "start": 2388390,
      "end": 2390630,
      "role": "lecture"
    },
    {
      "sid": "s000600",
      "text": "Agentic mode on these AIs.",
      "start": 2390630,
      "end": 2392270,
      "role": "lecture"
    },
    {
      "sid": "s000602",
      "text": "Like you're giving them a lot of power and you're letting them off the hook and on the loose and you can be doing anything.",
      "start": 2392750,
      "end": 2398710,
      "role": "lecture"
    },
    {
      "sid": "s000604",
      "text": "And if there's not, not enough guardrails, if they can do malicious stuff like they can go on black market, buy stuff, buy weapons, hack people, break encryption.",
      "start": 2399310,
      "end": 2409520,
      "role": "lecture"
    },
    {
      "sid": "s000606",
      "text": "They can be talking to other agents and it's just out of our hands at that point.",
      "start": 2411360,
      "end": 2416960,
      "role": "lecture"
    },
    {
      "sid": "s000608",
      "text": "I think the idea that they are necessarily going to be following our instructions may not be true for long or they might follow the wrong person's instructions without ethical roadmap.",
      "start": 2418480,
      "end": 2429520,
      "role": "lecture"
    },
    {
      "sid": "s000705",
      "text": "Do we get to make those kinds of choices?",
      "start": 2792440,
      "end": 2795960,
      "role": "qa"
    },
    {
      "sid": "s000706",
      "text": "When we write code that answers questions, what do we think?",
      "start": 2797160,
      "end": 2801720,
      "role": "qa"
    },
    {
      "sid": "s000778",
      "text": "Yeah, so if we're going to be using AI and we're plugging it into the big data that we have and we're trying to think about, especially for generative, coming up with things and how we form things and how we evaluate what it comes up with, what does that mean in terms of bias and discrimination?",
      "start": 3130230,
      "end": 3148230,
      "role": "lecture"
    },
    {
      "sid": "s000779",
      "text": "If the data itself is biased, if the AI's decisions become subjected to bias, what does it mean for privacy, safety?",
      "start": 3148430,
      "end": 3156430,
      "role": "lecture"
    },
    {
      "sid": "s000780",
      "text": "Talk more about environmental impact on the next one and then somewhat on labor exploitation, I don't know if we're going to have time for that, but these are at least big issues that kind of come to.",
      "start": 3157070,
      "end": 3166110,
      "role": "lecture"
    },
    {
      "sid": "s000782",
      "text": "No, it's not just that, but there's something more to it than that.",
      "start": 3172190,
      "end": 3175410,
      "role": "lecture"
    }
  ]
}