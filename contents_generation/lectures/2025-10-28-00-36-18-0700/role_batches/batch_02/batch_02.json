[
  {
    "context_before_main_text": [
      {
        "sid": "s000253",
        "text": "A lot of them are forced into it, of course.",
        "start": 914560,
        "end": 915920,
        "speaker": "A"
      },
      {
        "sid": "s000254",
        "text": "Right.",
        "start": 915920,
        "end": 916240,
        "speaker": "A"
      },
      {
        "sid": "s000255",
        "text": "So it's like, you know, how can you judge the actions?",
        "start": 916240,
        "end": 919560,
        "speaker": "A"
      },
      {
        "sid": "s000256",
        "text": "Okay.",
        "start": 922200,
        "end": 922760,
        "speaker": "E"
      },
      {
        "sid": "s000257",
        "text": "Participation time.",
        "start": 925320,
        "end": 926440,
        "speaker": "A"
      },
      {
        "sid": "s000258",
        "text": "Trying to get a sense for the room.",
        "start": 929170,
        "end": 930290,
        "speaker": "A"
      },
      {
        "sid": "s000259",
        "text": "Super intelligent AI, right?",
        "start": 930290,
        "end": 931810,
        "speaker": "A"
      },
      {
        "sid": "s000260",
        "text": "This idea that there's a singularity event where we continue to keep putting more and more into it and it exceeds our intelligence.",
        "start": 931810,
        "end": 938690,
        "speaker": "A"
      },
      {
        "sid": "s000261",
        "text": "Right.",
        "start": 938690,
        "end": 938930,
        "speaker": "A"
      },
      {
        "sid": "s000262",
        "text": "Not just it can beat me in chess.",
        "start": 938930,
        "end": 940250,
        "speaker": "A"
      }
    ],
    "main_text": [
      {
        "sid": "s000263",
        "text": "It's already there.",
        "start": 940250,
        "end": 940930,
        "speaker": "A"
      },
      {
        "sid": "s000264",
        "text": "There's certain.",
        "start": 941650,
        "end": 942370,
        "speaker": "A"
      },
      {
        "sid": "s000265",
        "text": "We kind of hope that we still have things that we have that we can do better.",
        "start": 942850,
        "end": 946770,
        "speaker": "A"
      },
      {
        "sid": "s000266",
        "text": "At least I can do it more power, efficiently maybe, but how concerned are you with the AI?",
        "start": 947490,
        "end": 951970,
        "speaker": "A"
      },
      {
        "sid": "s000267",
        "text": "So first of all, no concerns.",
        "start": 951970,
        "end": 953250,
        "speaker": "A"
      },
      {
        "sid": "s000268",
        "text": "It's not going to be intelligent the same way that we are.",
        "start": 953410,
        "end": 955980,
        "speaker": "A"
      },
      {
        "sid": "s000269",
        "text": "Maybe because the medium is different.",
        "start": 955980,
        "end": 957900,
        "speaker": "A"
      },
      {
        "sid": "s000270",
        "text": "You know, it lacks the hormones that make our intelligence somewhat more emotionally intelligent than that.",
        "start": 958140,
        "end": 965180,
        "speaker": "A"
      },
      {
        "sid": "s000271",
        "text": "It won't be the same sentient the same way that we are.",
        "start": 965340,
        "end": 968140,
        "speaker": "A"
      },
      {
        "sid": "s000272",
        "text": "Some concerns, look, we've got to figure out guardrails.",
        "start": 968700,
        "end": 971580,
        "speaker": "A"
      },
      {
        "sid": "s000273",
        "text": "We've got to kind of approach this technology in a reasonable way.",
        "start": 971580,
        "end": 974380,
        "speaker": "A"
      },
      {
        "sid": "s000274",
        "text": "Major concerns.",
        "start": 975100,
        "end": 976060,
        "speaker": "A"
      },
      {
        "sid": "s000275",
        "text": "If we don't understand how it works, how it's making decisions, this intellectual debt that I talked about about is going to be a real problem.",
        "start": 976060,
        "end": 982500,
        "speaker": "A"
      },
      {
        "sid": "s000276",
        "text": "Panic in the Matrix already.",
        "start": 982740,
        "end": 984260,
        "speaker": "A"
      },
      {
        "sid": "s000277",
        "text": "Or I'm not, I'm not.",
        "start": 984260,
        "end": 985860,
        "speaker": "A"
      },
      {
        "sid": "s000278",
        "text": "I'm not captured by this particular problem.",
        "start": 985860,
        "end": 987540,
        "speaker": "A"
      },
      {
        "sid": "s000279",
        "text": "The Matrix.",
        "start": 987780,
        "end": 988500,
        "speaker": "A"
      },
      {
        "sid": "s000280",
        "text": "You all have seen that, right?",
        "start": 988500,
        "end": 989740,
        "speaker": "A"
      },
      {
        "sid": "s000281",
        "text": "I feel like every time I bring up a movie, you're like, what the hell are you talking about?",
        "start": 989740,
        "end": 992380,
        "speaker": "A"
      },
      {
        "sid": "s000282",
        "text": "Okay, but hopefully we've seen the Matrix.",
        "start": 992380,
        "end": 993780,
        "speaker": "A"
      },
      {
        "sid": "s000283",
        "text": "Okay, how many for a.",
        "start": 993780,
        "end": 997380,
        "speaker": "A"
      },
      {
        "sid": "s000284",
        "text": "Okay, all right.",
        "start": 998900,
        "end": 999900,
        "speaker": "A"
      },
      {
        "sid": "s000285",
        "text": "Why.",
        "start": 999900,
        "end": 1000100,
        "speaker": "A"
      },
      {
        "sid": "s000286",
        "text": "Why no concerns?",
        "start": 1000100,
        "end": 1001060,
        "speaker": "A"
      },
      {
        "sid": "s000287",
        "text": "Well, I think like, AI now, like, it's still not like really artificial intelligence.",
        "start": 1002020,
        "end": 1006140,
        "speaker": "D"
      },
      {
        "sid": "s000288",
        "text": "It's where like a neural network is like, trained on data.",
        "start": 1006140,
        "end": 1008750,
        "speaker": "D"
      },
      {
        "sid": "s000289",
        "text": "So, like, even though it's like doing things that we might not, like using ChatGPT, like, understand, like, there's probably someone out there who's like, working on like the model that does understand why it's making these decisions and it's like trained on, like, data that we created and just doing, like, what we want it to do.",
        "start": 1009070,
        "end": 1024030,
        "speaker": "D"
      },
      {
        "sid": "s000290",
        "text": "So at the end of the day, like, if we want it to be ethical, you could tell it to be ethical.",
        "start": 1024190,
        "end": 1028550,
        "speaker": "D"
      },
      {
        "sid": "s000291",
        "text": "If you don't want it to be ethical, we could tell that too.",
        "start": 1028550,
        "end": 1031310,
        "speaker": "D"
      },
      {
        "sid": "s000292",
        "text": "I think it was to still follow what you want.",
        "start": 1031310,
        "end": 1033000,
        "speaker": "D"
      },
      {
        "sid": "s000293",
        "text": "You think it still listens to us?",
        "start": 1033560,
        "end": 1035440,
        "speaker": "A"
      },
      {
        "sid": "s000294",
        "text": "Yeah.",
        "start": 1035440,
        "end": 1035880,
        "speaker": "A"
      },
      {
        "sid": "s000295",
        "text": "Okay, cool.",
        "start": 1035880,
        "end": 1036760,
        "speaker": "A"
      },
      {
        "sid": "s000296",
        "text": "Anyone else on that one?",
        "start": 1038440,
        "end": 1039680,
        "speaker": "A"
      },
      {
        "sid": "s000297",
        "text": "Okay, how about B?",
        "start": 1039680,
        "end": 1040440,
        "speaker": "A"
      },
      {
        "sid": "s000298",
        "text": "Some concerns?",
        "start": 1041240,
        "end": 1042040,
        "speaker": "A"
      },
      {
        "sid": "s000299",
        "text": "Yeah.",
        "start": 1042040,
        "end": 1042320,
        "speaker": "A"
      },
      {
        "sid": "s000300",
        "text": "Why?",
        "start": 1042320,
        "end": 1042600,
        "speaker": "A"
      },
      {
        "sid": "s000301",
        "text": "I mean, I think there's still, like, limited access to what I can do.",
        "start": 1044440,
        "end": 1049240,
        "speaker": "G"
      },
      {
        "sid": "s000302",
        "text": "Seem like, you know, certain companies, they're not applied to military.",
        "start": 1049800,
        "end": 1055640,
        "speaker": "A"
      },
      {
        "sid": "s000303",
        "text": "The more we get, how many think that that's worth.",
        "start": 1056600,
        "end": 1065960,
        "speaker": "A"
      },
      {
        "sid": "s000304",
        "text": "Okay, this is.",
        "start": 1065960,
        "end": 1066960,
        "speaker": "A"
      },
      {
        "sid": "s000305",
        "text": "This is a major concern.",
        "start": 1066960,
        "end": 1068000,
        "speaker": "A"
      },
      {
        "sid": "s000306",
        "text": "This is not just something minor.",
        "start": 1068160,
        "end": 1069600,
        "speaker": "A"
      },
      {
        "sid": "s000307",
        "text": "This is a real problem.",
        "start": 1069600,
        "end": 1070560,
        "speaker": "A"
      },
      {
        "sid": "s000308",
        "text": "I'm worried about it.",
        "start": 1070960,
        "end": 1071840,
        "speaker": "A"
      },
      {
        "sid": "s000309",
        "text": "My future's impacted.",
        "start": 1072240,
        "end": 1073440,
        "speaker": "A"
      },
      {
        "sid": "s000310",
        "text": "Intellectual debt's too much.",
        "start": 1074640,
        "end": 1075720,
        "speaker": "A"
      },
      {
        "sid": "s000311",
        "text": "What do we think?",
        "start": 1075720,
        "end": 1076240,
        "speaker": "A"
      },
      {
        "sid": "s000312",
        "text": "Who's really worried?",
        "start": 1076240,
        "end": 1077000,
        "speaker": "A"
      },
      {
        "sid": "s000313",
        "text": "C. Yes.",
        "start": 1077000,
        "end": 1078280,
        "speaker": "A"
      },
      {
        "sid": "s000314",
        "text": "Why?",
        "start": 1078280,
        "end": 1078640,
        "speaker": "A"
      },
      {
        "sid": "s000315",
        "text": "Just based on how much generative AI has improved in the last three years, if we keep going, then I do think AI could eventually become.",
        "start": 1081440,
        "end": 1095290,
        "speaker": "E"
      },
      {
        "sid": "s000316",
        "text": "In this.",
        "start": 1097770,
        "end": 1098130,
        "speaker": "A"
      },
      {
        "sid": "s000317",
        "text": "Case, smarter than us, in a sense.",
        "start": 1098130,
        "end": 1100210,
        "speaker": "E"
      },
      {
        "sid": "s000318",
        "text": "But also, I don't necessarily agree with the statement of we don't understand how Eddie's making.",
        "start": 1100210,
        "end": 1107370,
        "speaker": "E"
      },
      {
        "sid": "s000319",
        "text": "Because ultimately.",
        "start": 1108580,
        "end": 1109460,
        "speaker": "A"
      },
      {
        "sid": "s000320",
        "text": "Humans are the ones that train the AI.",
        "start": 1111220,
        "end": 1113220,
        "speaker": "E"
      },
      {
        "sid": "s000321",
        "text": "We give it the knowledge base that.",
        "start": 1113780,
        "end": 1115260,
        "speaker": "E"
      },
      {
        "sid": "s000322",
        "text": "It has.",
        "start": 1115260,
        "end": 1115700,
        "speaker": "A"
      },
      {
        "sid": "s000323",
        "text": "And ultimately we tell it what to do and whether or not it does it better than us, I guess.",
        "start": 1118420,
        "end": 1126420,
        "speaker": "E"
      },
      {
        "sid": "s000324",
        "text": "So.",
        "start": 1128260,
        "end": 1128500,
        "speaker": "A"
      },
      {
        "sid": "s000325",
        "text": "Let me ask you this.",
        "start": 1128500,
        "end": 1129260,
        "speaker": "A"
      },
      {
        "sid": "s000326",
        "text": "If we trained it, we gave it the data, I and I carefully.",
        "start": 1129260,
        "end": 1133220,
        "speaker": "A"
      },
      {
        "sid": "s000327",
        "text": "You know, it's kind of funny.",
        "start": 1133700,
        "end": 1134780,
        "speaker": "A"
      },
      {
        "sid": "s000328",
        "text": "As a parent, I can't.",
        "start": 1134940,
        "end": 1136540,
        "speaker": "A"
      },
      {
        "sid": "s000329",
        "text": "It's wrong.",
        "start": 1137340,
        "end": 1137900,
        "speaker": "A"
      },
      {
        "sid": "s000330",
        "text": "I can't think of this without thinking of my own kids.",
        "start": 1137900,
        "end": 1140220,
        "speaker": "A"
      },
      {
        "sid": "s000331",
        "text": "Right.",
        "start": 1140220,
        "end": 1140620,
        "speaker": "A"
      },
      {
        "sid": "s000332",
        "text": "I put them in an environment and I told them only good things, so they should only be doing good stuff.",
        "start": 1140780,
        "end": 1145500,
        "speaker": "A"
      },
      {
        "sid": "s000333",
        "text": "Right.",
        "start": 1145500,
        "end": 1145740,
        "speaker": "A"
      },
      {
        "sid": "s000334",
        "text": "I feel like there's a similarity here, and I hate to make the analogy because this is not alive.",
        "start": 1145980,
        "end": 1149860,
        "speaker": "A"
      },
      {
        "sid": "s000335",
        "text": "It's not sentient.",
        "start": 1149860,
        "end": 1150780,
        "speaker": "A"
      },
      {
        "sid": "s000336",
        "text": "But to me, it's similar to what you're saying.",
        "start": 1151020,
        "end": 1153020,
        "speaker": "A"
      },
      {
        "sid": "s000337",
        "text": "I have told it what to do.",
        "start": 1153740,
        "end": 1155660,
        "speaker": "A"
      },
      {
        "sid": "s000338",
        "text": "I've given it data that I curated and gave it carefully.",
        "start": 1155980,
        "end": 1159260,
        "speaker": "A"
      },
      {
        "sid": "s000339",
        "text": "So of course I'll understand it as decisions that it makes.",
        "start": 1159500,
        "end": 1162020,
        "speaker": "A"
      },
      {
        "sid": "s000340",
        "text": "Right?",
        "start": 1162020,
        "end": 1162380,
        "speaker": "A"
      },
      {
        "sid": "s000341",
        "text": "But the reality is it's a mathematical model where weights are being applied to an architecture that's a neural network architecture, where the mathematical models I may not be able to fully grasp.",
        "start": 1162460,
        "end": 1174140,
        "speaker": "A"
      },
      {
        "sid": "s000342",
        "text": "Did I give it enough of this example?",
        "start": 1174380,
        "end": 1176060,
        "speaker": "A"
      },
      {
        "sid": "s000343",
        "text": "Did I give it enough of that?",
        "start": 1176060,
        "end": 1177180,
        "speaker": "A"
      },
      {
        "sid": "s000344",
        "text": "Is it brittle because I didn't test all the parameters?",
        "start": 1177660,
        "end": 1181260,
        "speaker": "A"
      },
      {
        "sid": "s000345",
        "text": "So in terms of my understanding of some mathematical model that was taken by throwing enough examples of something at it, how much do I really get it?",
        "start": 1181980,
        "end": 1191280,
        "speaker": "A"
      },
      {
        "sid": "s000346",
        "text": "I think that's a concern.",
        "start": 1191840,
        "end": 1192800,
        "speaker": "A"
      },
      {
        "sid": "s000347",
        "text": "The people think I'm wrong and maybe we agree that we built it, we should get it, what's the big deal?",
        "start": 1193120,
        "end": 1198640,
        "speaker": "A"
      },
      {
        "sid": "s000348",
        "text": "Yeah.",
        "start": 1199920,
        "end": 1200400,
        "speaker": "A"
      },
      {
        "sid": "s000349",
        "text": "I guess my thinking is there's always going to be one person, no matter how smart.",
        "start": 1202160,
        "end": 1208320,
        "speaker": "E"
      },
      {
        "sid": "s000350",
        "text": "So there's still one.",
        "start": 1209280,
        "end": 1210720,
        "speaker": "A"
      },
      {
        "sid": "s000351",
        "text": "This one person, you're saying is able to interpret the mathematical models of what it's putting out there enough that they could discern like could they predict its answer on a particular question?",
        "start": 1210720,
        "end": 1222580,
        "speaker": "A"
      },
      {
        "sid": "s000352",
        "text": "I would assume yes.",
        "start": 1223380,
        "end": 1224740,
        "speaker": "E"
      },
      {
        "sid": "s000353",
        "text": "What do you think?",
        "start": 1226740,
        "end": 1227540,
        "speaker": "A"
      },
      {
        "sid": "s000354",
        "text": "What do you think?",
        "start": 1232100,
        "end": 1232740,
        "speaker": "A"
      },
      {
        "sid": "s000355",
        "text": "I think it's like very improbable that.",
        "start": 1232740,
        "end": 1234460,
        "speaker": "E"
      },
      {
        "sid": "s000356",
        "text": "Someone could actually do it.",
        "start": 1234460,
        "end": 1235540,
        "speaker": "C"
      },
      {
        "sid": "s000357",
        "text": "Like someone could actually like fully understand the model because like that's like a modern model.",
        "start": 1235540,
        "end": 1240340,
        "speaker": "C"
      },
      {
        "sid": "s000358",
        "text": "Like maybe if you use a smaller model like GPT2 or something, maybe you can understand what's going on.",
        "start": 1240340,
        "end": 1244940,
        "speaker": "C"
      },
      {
        "sid": "s000359",
        "text": "But if you look at a modern model has trillions of parameters.",
        "start": 1245100,
        "end": 1247940,
        "speaker": "C"
      },
      {
        "sid": "s000360",
        "text": "Like let's say you actually wanted to understand what every single one of them does.",
        "start": 1247940,
        "end": 1251100,
        "speaker": "C"
      },
      {
        "sid": "s000361",
        "text": "You have to think in some way higher dimensional space and you don't actually understand what is being captured by those weights that you know.",
        "start": 1251180,
        "end": 1258940,
        "speaker": "C"
      },
      {
        "sid": "s000362",
        "text": "Okay, maybe this section is responsible for this.",
        "start": 1259100,
        "end": 1261860,
        "speaker": "C"
      },
      {
        "sid": "s000363",
        "text": "You like a patient testing or something.",
        "start": 1261860,
        "end": 1263500,
        "speaker": "C"
      },
      {
        "sid": "s000364",
        "text": "Right.",
        "start": 1263580,
        "end": 1263980,
        "speaker": "A"
      },
      {
        "sid": "s000365",
        "text": "You can't actually know what every single parameter is contributing to the model.",
        "start": 1264530,
        "end": 1268970,
        "speaker": "C"
      },
      {
        "sid": "s000366",
        "text": "So there's not really a good way for someone to know everything about.",
        "start": 1268970,
        "end": 1272370,
        "speaker": "C"
      },
      {
        "sid": "s000367",
        "text": "Sorry.",
        "start": 1273970,
        "end": 1274450,
        "speaker": "A"
      },
      {
        "sid": "s000368",
        "text": "How comfortable are we with transformer like models?",
        "start": 1274450,
        "end": 1276890,
        "speaker": "A"
      },
      {
        "sid": "s000369",
        "text": "Are we feeling pretty good about it?",
        "start": 1276890,
        "end": 1278450,
        "speaker": "A"
      },
      {
        "sid": "s000370",
        "text": "I've got some slides that I'm not saying I'm going to get into back propagation algorithms, just high level kind of giving you a sense for the scope of it.",
        "start": 1279010,
        "end": 1288050,
        "speaker": "A"
      },
      {
        "sid": "s000371",
        "text": "Is that something that's helpful or not?",
        "start": 1288050,
        "end": 1289490,
        "speaker": "A"
      },
      {
        "sid": "s000372",
        "text": "Give a second.",
        "start": 1289970,
        "end": 1290720,
        "speaker": "A"
      },
      {
        "sid": "s000373",
        "text": "So maximum pass is the pass.",
        "start": 1291920,
        "end": 1294080,
        "speaker": "E"
      },
      {
        "sid": "s000374",
        "text": "I have something go through the.",
        "start": 1294720,
        "end": 1299800,
        "speaker": "A"
      },
      {
        "sid": "s000375",
        "text": "No, there may be some overlapping but I will skip that.",
        "start": 1299800,
        "end": 1305200,
        "speaker": "A"
      },
      {
        "sid": "s000376",
        "text": "No, if all collectible.",
        "start": 1307440,
        "end": 1309600,
        "speaker": "E"
      },
      {
        "sid": "s000377",
        "text": "Yeah.",
        "start": 1309600,
        "end": 1310080,
        "speaker": "A"
      },
      {
        "sid": "s000378",
        "text": "No, no, no.",
        "start": 1310160,
        "end": 1310960,
        "speaker": "A"
      },
      {
        "sid": "s000379",
        "text": "Okay.",
        "start": 1313440,
        "end": 1313880,
        "speaker": "A"
      },
      {
        "sid": "s000380",
        "text": "I took this from a.",
        "start": 1313880,
        "end": 1315120,
        "speaker": "A"
      },
      {
        "sid": "s000381",
        "text": "There exist a positive three brown one.",
        "start": 1315930,
        "end": 1319050,
        "speaker": "E"
      },
      {
        "sid": "s000382",
        "text": "Blue presentation plus some other stuff that I really like.",
        "start": 1319050,
        "end": 1323010,
        "speaker": "A"
      },
      {
        "sid": "s000383",
        "text": "The way he described my.",
        "start": 1323010,
        "end": 1324170,
        "speaker": "A"
      },
      {
        "sid": "s000384",
        "text": "So what's that?",
        "start": 1324490,
        "end": 1327370,
        "speaker": "A"
      },
      {
        "sid": "s000385",
        "text": "It's the other way.",
        "start": 1327450,
        "end": 1328210,
        "speaker": "A"
      },
      {
        "sid": "s000386",
        "text": "Oh it's.",
        "start": 1328210,
        "end": 1328610,
        "speaker": "A"
      },
      {
        "sid": "s000387",
        "text": "It's three blue, one brown.",
        "start": 1328610,
        "end": 1329650,
        "speaker": "A"
      },
      {
        "sid": "s000388",
        "text": "My bad, my bad.",
        "start": 1329650,
        "end": 1330730,
        "speaker": "A"
      },
      {
        "sid": "s000389",
        "text": "I can't remember.",
        "start": 1331050,
        "end": 1331770,
        "speaker": "A"
      },
      {
        "sid": "s000390",
        "text": "Connected under.",
        "start": 1333610,
        "end": 1334410,
        "speaker": "E"
      },
      {
        "sid": "s000391",
        "text": "So let's skip ahead to what a generative perspective.",
        "start": 1334570,
        "end": 1342180,
        "speaker": "A"
      },
      {
        "sid": "s000392",
        "text": "Pre trained transformers GPT.",
        "start": 1342250,
        "end": 1344010,
        "speaker": "A"
      },
      {
        "sid": "s000393",
        "text": "Okay.",
        "start": 1344330,
        "end": 1344890,
        "speaker": "A"
      },
      {
        "sid": "s000394",
        "text": "Generative in the sense that it can generate new text.",
        "start": 1345210,
        "end": 1347450,
        "speaker": "A"
      },
      {
        "sid": "s000395",
        "text": "Pre trained in the sense that it is trained on a massive amount of data but it's still supposed to be learning and adapting.",
        "start": 1348010,
        "end": 1354930,
        "speaker": "A"
      },
      {
        "sid": "s000396",
        "text": "So there is some baked in understanding to start.",
        "start": 1354930,
        "end": 1357690,
        "speaker": "A"
      },
      {
        "sid": "s000397",
        "text": "It's not just starting tabula rasa as like a deep learning like alpha zero alpha transformer originally and I know there's been a lot of innovation that's kind of pushed this down, but just the basic transformer architecture was transforming one language into another, right?",
        "start": 1357690,
        "end": 1379220,
        "speaker": "A"
      },
      {
        "sid": "s000398",
        "text": "And now instead of it just doing that, it's looking at context and coming up with what is the probabilistic distribution of what comes next.",
        "start": 1380500,
        "end": 1390740,
        "speaker": "A"
      },
      {
        "sid": "s000399",
        "text": "Again, high level of what it does.",
        "start": 1391860,
        "end": 1394710,
        "speaker": "A"
      },
      {
        "sid": "s000400",
        "text": "The big picture is that it tries to understand that context by breaking things down into pieces.",
        "start": 1395510,
        "end": 1401670,
        "speaker": "A"
      },
      {
        "sid": "s000401",
        "text": "So for this kind of sentence, it'll break it up into tokens or individual pieces.",
        "start": 1401830,
        "end": 1406470,
        "speaker": "A"
      },
      {
        "sid": "s000402",
        "text": "I broke it by words.",
        "start": 1406470,
        "end": 1407830,
        "speaker": "A"
      },
      {
        "sid": "s000403",
        "text": "But it doesn't have to be at the level of words, but it tries to figure out what each piece of a particular context means.",
        "start": 1407830,
        "end": 1414950,
        "speaker": "A"
      },
      {
        "sid": "s000404",
        "text": "And the way it does that is first looking at the word in isolation.",
        "start": 1415590,
        "end": 1419350,
        "speaker": "A"
      },
      {
        "sid": "s000405",
        "text": "And so in this case, shoots in this particular sentence could have a variety of meanings, from tender bamboo shoots to a photo shoot to shooting with the bow and arrow or something else.",
        "start": 1419930,
        "end": 1429610,
        "speaker": "A"
      },
      {
        "sid": "s000406",
        "text": "And so what that panda is doing is there could be many different interpretations that could exist without additional context or clarity.",
        "start": 1430410,
        "end": 1439690,
        "speaker": "A"
      },
      {
        "sid": "s000407",
        "text": "So what they try to do is they try and figure out, based on the context, the understanding of the pre trained transformer carries of the world and everything else, what does that actually mean.",
        "start": 1440890,
        "end": 1452080,
        "speaker": "A"
      },
      {
        "sid": "s000408",
        "text": "And so that's broken up into pieces of tokenizing, the individual input, embedding what the word means into some mathematical language, using attention so that you can find all the other context and how that manipulates that mathematical model and then going through layers and layers of perceptrons.",
        "start": 1453200,
        "end": 1470880,
        "speaker": "A"
      },
      {
        "sid": "s000409",
        "text": "And this is where I would argue that even the smartest person would have a very hard time looking at this and piecing it together.",
        "start": 1471450,
        "end": 1479050,
        "speaker": "A"
      },
      {
        "sid": "s000410",
        "text": "So I think you all understand tokenizing.",
        "start": 1480170,
        "end": 1483370,
        "speaker": "A"
      },
      {
        "sid": "s000411",
        "text": "And so the idea is that you're taking pieces and you're making it into math.",
        "start": 1483770,
        "end": 1487489,
        "speaker": "A"
      },
      {
        "sid": "s000412",
        "text": "So let me go with my friend here who made this beautiful diagram.",
        "start": 1487489,
        "end": 1490250,
        "speaker": "A"
      },
      {
        "sid": "s000413",
        "text": "It's kind of hard to read here, but the idea is that for all these different words, they are embedded as a matrix of numbers.",
        "start": 1490250,
        "end": 1496250,
        "speaker": "A"
      },
      {
        "sid": "s000414",
        "text": "And once you have this matrix of numbers, what you can do is you can represent that in space.",
        "start": 1497140,
        "end": 1503940,
        "speaker": "A"
      },
      {
        "sid": "s000415",
        "text": "If this was only a 3D matrix, it would be fine.",
        "start": 1504260,
        "end": 1507260,
        "speaker": "A"
      },
      {
        "sid": "s000416",
        "text": "You could represent it in a three dimensional space, but this particular matrix that we're talking about is far greater.",
        "start": 1507260,
        "end": 1514660,
        "speaker": "A"
      },
      {
        "sid": "s000417",
        "text": "But let's just think about the 3D for a second.",
        "start": 1514900,
        "end": 1516900,
        "speaker": "A"
      },
      {
        "sid": "s000418",
        "text": "If I have words that are represented as vectors in that 3D space, you could think about it as being multiple.",
        "start": 1517060,
        "end": 1522480,
        "speaker": "A"
      },
      {
        "sid": "s000419",
        "text": "So that maybe the default of shirt is here, but if I look at a particular shirt, a black shirt, it's different in space, versus a white Shirt or a blue shirt.",
        "start": 1523190,
        "end": 1532070,
        "speaker": "A"
      },
      {
        "sid": "s000420",
        "text": "And so what happens is that the embedding we have for these words is truly massive.",
        "start": 1533270,
        "end": 1539270,
        "speaker": "A"
      },
      {
        "sid": "s000421",
        "text": "Because when I put these different words in, into the embedding and I have these different vectors, I can grow and shrink what they are in the space depending on the types of attention that's paid to them.",
        "start": 1541990,
        "end": 1553190,
        "speaker": "A"
      },
      {
        "sid": "s000422",
        "text": "So this is the weights on individual words tweaking as the mathematical model changes for what the word means.",
        "start": 1555430,
        "end": 1563590,
        "speaker": "A"
      },
      {
        "sid": "s000423",
        "text": "Maybe shirt means something at first, but when I'm talking about context and I put Glenn's shirt in front of it, it's this particular shirt, the general concept of a shirt.",
        "start": 1563670,
        "end": 1572710,
        "speaker": "A"
      },
      {
        "sid": "s000424",
        "text": "So the way that works is, is an example here.",
        "start": 1573590,
        "end": 1576480,
        "speaker": "A"
      },
      {
        "sid": "s000425",
        "text": "If I look at the word tower and I look at all the words that are close to it, it could be close in that multidimensional space.",
        "start": 1576720,
        "end": 1584480,
        "speaker": "A"
      },
      {
        "sid": "s000426",
        "text": "So that things that are similar kind of fit into the same space in the coordinate plane.",
        "start": 1584960,
        "end": 1590480,
        "speaker": "A"
      },
      {
        "sid": "s000427",
        "text": "And what that means is when you have embeddings that have association, like I compare sushi to Japan, and I compare, maybe bratwurst to Germany, there's an association or a distance that makes sense across those spaces.",
        "start": 1591600,
        "end": 1607110,
        "speaker": "A"
      },
      {
        "sid": "s000428",
        "text": "Does that make sense?",
        "start": 1607270,
        "end": 1608150,
        "speaker": "A"
      },
      {
        "sid": "s000429",
        "text": "So these words in this multi dimensional space have meaning even when you compare them in this sort of matrix, multiple matrix addition and subtraction.",
        "start": 1608950,
        "end": 1617270,
        "speaker": "A"
      },
      {
        "sid": "s000430",
        "text": "So I think what makes things really challenging is this notion of attention.",
        "start": 1617910,
        "end": 1621510,
        "speaker": "A"
      },
      {
        "sid": "s000431",
        "text": "So you've got your tokens, words, you break them up in terms of a mathematical model that can be adjusted in terms of weights, and you pay attention to them.",
        "start": 1621990,
        "end": 1630660,
        "speaker": "A"
      },
      {
        "sid": "s000432",
        "text": "So the word quill, which could mean a porcupine quill or a writing quill, will take its meaning from the sentences that surround it.",
        "start": 1631460,
        "end": 1640580,
        "speaker": "A"
      },
      {
        "sid": "s000433",
        "text": "All of these different parts from multiple areas will inform what that word means.",
        "start": 1641140,
        "end": 1647140,
        "speaker": "A"
      },
      {
        "sid": "s000434",
        "text": "When you read the context of something, it disambiguates the word fair.",
        "start": 1647540,
        "end": 1651300,
        "speaker": "A"
      },
      {
        "sid": "s000435",
        "text": "So similarly, if you see the word mole, if you think about the different vectors, that word mole might start at the same exact value.",
        "start": 1653870,
        "end": 1663070,
        "speaker": "A"
      },
      {
        "sid": "s000436",
        "text": "As a token, the embedding of mole will start with a certain set of coordinates in this multidimensional space.",
        "start": 1663390,
        "end": 1670830,
        "speaker": "A"
      },
      {
        "sid": "s000437",
        "text": "But when I pick a particular interpretation, so a mole of carbon dioxide, the attention of the other words will start to play in and change that particular value for mole.",
        "start": 1671950,
        "end": 1683500,
        "speaker": "A"
      },
      {
        "sid": "s000438",
        "text": "It'll reorient it to be something in the chemical domain instead of just a generic mole.",
        "start": 1683980,
        "end": 1688460,
        "speaker": "A"
      },
      {
        "sid": "s000439",
        "text": "And so what you would have is, for example, if this is the embedding space of a mole of carbon dioxide, it might start at conventional general mole and then move in that space towards what a particular mole is.",
        "start": 1689740,
        "end": 1702700,
        "speaker": "A"
      },
      {
        "sid": "s000440",
        "text": "Just like it might move differently if it were the animal and move to a different dimension.",
        "start": 1703100,
        "end": 1710630,
        "speaker": "A"
      },
      {
        "sid": "s000441",
        "text": "So attention is the influence on the weights mathematically.",
        "start": 1711670,
        "end": 1715670,
        "speaker": "A"
      },
      {
        "sid": "s000442",
        "text": "Right.",
        "start": 1716070,
        "end": 1716470,
        "speaker": "A"
      },
      {
        "sid": "s000443",
        "text": "Any questions so far?",
        "start": 1717910,
        "end": 1718830,
        "speaker": "A"
      },
      {
        "sid": "s000444",
        "text": "I'm going through this really fast.",
        "start": 1718830,
        "end": 1719790,
        "speaker": "A"
      },
      {
        "sid": "s000445",
        "text": "I know I have to get the evidence, but I wanted to at least give this concept.",
        "start": 1719790,
        "end": 1723430,
        "speaker": "A"
      },
      {
        "sid": "s000446",
        "text": "So a perceptron.",
        "start": 1725270,
        "end": 1726470,
        "speaker": "A"
      },
      {
        "sid": "s000447",
        "text": "Does everybody have a good basic understanding of what machine learning is?",
        "start": 1726710,
        "end": 1729990,
        "speaker": "A"
      },
      {
        "sid": "s000448",
        "text": "Okay, so the example that I use with people who don't necessarily is how do I get distinguished between different models?",
        "start": 1731040,
        "end": 1741880,
        "speaker": "A"
      },
      {
        "sid": "s000449",
        "text": "I stole this one thing.",
        "start": 1741880,
        "end": 1742800,
        "speaker": "A"
      },
      {
        "sid": "s000450",
        "text": "This is an ethics class and I'm stealing people.",
        "start": 1743760,
        "end": 1745600,
        "speaker": "A"
      },
      {
        "sid": "s000451",
        "text": "Okay, so in this particular case, if I had an entomologist, an entomologist, and I put them out into the field and I wanted them to tell me how can I tell the difference between two different types of moths.",
        "start": 1745680,
        "end": 1757970,
        "speaker": "A"
      },
      {
        "sid": "s000452",
        "text": "They might be able to grab moths, measure their wingspan and mass, and come up with this plot from Give me all this data.",
        "start": 1758450,
        "end": 1766450,
        "speaker": "A"
      },
      {
        "sid": "s000453",
        "text": "And I have labeled data that knows exactly what different types of things are.",
        "start": 1767090,
        "end": 1771730,
        "speaker": "A"
      },
      {
        "sid": "s000454",
        "text": "And then I can have my amazing machine model come and figure out with other factors as well, perhaps like the length of the antenna, how you partition the space to.",
        "start": 1772050,
        "end": 1782070,
        "speaker": "A"
      },
      {
        "sid": "s000455",
        "text": "To learn differences across that region.",
        "start": 1782220,
        "end": 1784060,
        "speaker": "A"
      },
      {
        "sid": "s000456",
        "text": "And there's all kinds of cool examples of how we can build our neural networks to do that.",
        "start": 1784700,
        "end": 1788180,
        "speaker": "A"
      },
      {
        "sid": "s000457",
        "text": "And it gets worse.",
        "start": 1788180,
        "end": 1789020,
        "speaker": "A"
      },
      {
        "sid": "s000458",
        "text": "If there's all different kinds of mops, we can still try to figure out a partitioning that makes sense.",
        "start": 1789260,
        "end": 1794060,
        "speaker": "A"
      },
      {
        "sid": "s000459",
        "text": "So what does that mean ultimately for us is it's a decision model.",
        "start": 1795420,
        "end": 1800380,
        "speaker": "A"
      },
      {
        "sid": "s000460",
        "text": "We've got a collection of inputs that come in and based on training data, we produce some output.",
        "start": 1801340,
        "end": 1806580,
        "speaker": "A"
      },
      {
        "sid": "s000461",
        "text": "And I think doing.",
        "start": 1806580,
        "end": 1807600,
        "speaker": "A"
      },
      {
        "sid": "s000462",
        "text": "Do most of you have an idea of what a perceptron is?",
        "start": 1807670,
        "end": 1810630,
        "speaker": "A"
      },
      {
        "sid": "s000463",
        "text": "It's based off of a neuron.",
        "start": 1811190,
        "end": 1812710,
        "speaker": "A"
      },
      {
        "sid": "s000464",
        "text": "It's got inputs that are weighted by a certain amount that is programmable.",
        "start": 1813110,
        "end": 1816470,
        "speaker": "A"
      },
      {
        "sid": "s000465",
        "text": "And all those collection of inputs will either trigger or not trigger an output.",
        "start": 1816950,
        "end": 1820630,
        "speaker": "A"
      },
      {
        "sid": "s000466",
        "text": "I like to view it as a very robust automatic door that may have a combination of pressure and weight, infrared and motion detection.",
        "start": 1821110,
        "end": 1831430,
        "speaker": "A"
      },
      {
        "sid": "s000467",
        "text": "And for that door to open, there may be a combination of inputs that are considered to find if someone's there.",
        "start": 1831750,
        "end": 1839180,
        "speaker": "A"
      },
      {
        "sid": "s000468",
        "text": "But we might change the weighting so that maybe pressure is the biggest indicator.",
        "start": 1839340,
        "end": 1843420,
        "speaker": "A"
      },
      {
        "sid": "s000469",
        "text": "That's the kind of flexibility that we're trying to figure out is which one of those inputs is the most important for the decision that we're making.",
        "start": 1844300,
        "end": 1851420,
        "speaker": "A"
      },
      {
        "sid": "s000470",
        "text": "So just to give you the context, this is an example of a neural network that tries to figure out handwriting.",
        "start": 1852620,
        "end": 1858940,
        "speaker": "A"
      },
      {
        "sid": "s000471",
        "text": "It's a challenging problem, but let's say that I give you all of the numbers that are in that in terms of weights could you look even at this and tell me how accurate it would be.",
        "start": 1860690,
        "end": 1871890,
        "speaker": "A"
      },
      {
        "sid": "s000472",
        "text": "It would be really challenging, right?",
        "start": 1872290,
        "end": 1873890,
        "speaker": "A"
      },
      {
        "sid": "s000473",
        "text": "Maybe as a user I can say, oh, I know how this works with back propagation, I figure out what the actual value is that it should have gone and I work my way backwards.",
        "start": 1874130,
        "end": 1883050,
        "speaker": "A"
      },
      {
        "sid": "s000474",
        "text": "My algorithm, I can understand the algorithm, but given the input, given the weights, can I say anything with any certainty about whether this thing works?",
        "start": 1883050,
        "end": 1894240,
        "speaker": "A"
      },
      {
        "sid": "s000475",
        "text": "That's what's so hard.",
        "start": 1894640,
        "end": 1895760,
        "speaker": "A"
      },
      {
        "sid": "s000476",
        "text": "And it's still.",
        "start": 1896960,
        "end": 1897760,
        "speaker": "A"
      },
      {
        "sid": "s000477",
        "text": "This is another example, but let me give you the basic view of the transformer, just to give you the sense.",
        "start": 1898800,
        "end": 1904720,
        "speaker": "A"
      },
      {
        "sid": "s000478",
        "text": "This is where I was really going for this slide.",
        "start": 1904720,
        "end": 1906400,
        "speaker": "A"
      },
      {
        "sid": "s000479",
        "text": "If you've got the input tokenizing coming up with attention, starting this mathematical model, what you have attached onto it are multi layer perceptrons that are being trained over time.",
        "start": 1907360,
        "end": 1920290,
        "speaker": "A"
      },
      {
        "sid": "s000480",
        "text": "This is the pre trained part with its understanding of the world.",
        "start": 1920370,
        "end": 1923570,
        "speaker": "A"
      },
      {
        "sid": "s000481",
        "text": "And if it was just this, I think alone, we would have a problem.",
        "start": 1924370,
        "end": 1927810,
        "speaker": "A"
      },
      {
        "sid": "s000482",
        "text": "But it's not.",
        "start": 1928050,
        "end": 1928850,
        "speaker": "A"
      },
      {
        "sid": "s000483",
        "text": "It's actually much worse than that because then what happens is we go through another round of attention and then we go through more perceptron and as many, many repetitions to refine the answer in order to finally get that ultimate piece out.",
        "start": 1929090,
        "end": 1942270,
        "speaker": "A"
      },
      {
        "sid": "s000484",
        "text": "And with all of that ridiculous amount of perceptrons and attention and everything else, just to get that one answer that dumps out.",
        "start": 1943470,
        "end": 1952190,
        "speaker": "A"
      },
      {
        "sid": "s000485",
        "text": "I think the problem is how would we possibly be able to figure things in scope of graph?",
        "start": 1952750,
        "end": 1957150,
        "speaker": "A"
      },
      {
        "sid": "s000486",
        "text": "Does that make sense?",
        "start": 1957150,
        "end": 1957950,
        "speaker": "A"
      },
      {
        "sid": "s000487",
        "text": "I think the other one, yeah.",
        "start": 1960910,
        "end": 1963810,
        "speaker": "A"
      },
      {
        "sid": "s000488",
        "text": "In terms of a modern LLM, GPT4 had over a trillion parameters.",
        "start": 1963810,
        "end": 1969290,
        "speaker": "A"
      },
      {
        "sid": "s000489",
        "text": "So even a model that's two years old at this point, who can look at a trillion parameters and make some sense out of it?",
        "start": 1969690,
        "end": 1976490,
        "speaker": "A"
      },
      {
        "sid": "s000490",
        "text": "Not possible.",
        "start": 1977610,
        "end": 1978250,
        "speaker": "A"
      },
      {
        "sid": "s000491",
        "text": "Not reasonable.",
        "start": 1978730,
        "end": 1979530,
        "speaker": "A"
      },
      {
        "sid": "s000492",
        "text": "Here's another movie that most of you probably haven't heard of.",
        "start": 1983770,
        "end": 1985930,
        "speaker": "A"
      },
      {
        "sid": "s000493",
        "text": "Have any even seen Groundhog Day?",
        "start": 1985930,
        "end": 1987370,
        "speaker": "A"
      },
      {
        "sid": "s000494",
        "text": "Okay, we're finally getting into the lexicon.",
        "start": 1988170,
        "end": 1991320,
        "speaker": "A"
      },
      {
        "sid": "s000495",
        "text": "Okay, great.",
        "start": 1991320,
        "end": 1991800,
        "speaker": "A"
      },
      {
        "sid": "s000496",
        "text": "One approach of thinking about how to train these machines is I think, Groundhog Day.",
        "start": 1992520,
        "end": 1997760,
        "speaker": "A"
      },
      {
        "sid": "s000497",
        "text": "I think this to me is the ultimate analogy for training an LLM.",
        "start": 1997760,
        "end": 2001400,
        "speaker": "A"
      },
      {
        "sid": "s000498",
        "text": "This dude spent by one estimate, 8 years and 8 months and 16 days reliving the same day over and over again.",
        "start": 2001640,
        "end": 2007720,
        "speaker": "A"
      },
      {
        "sid": "s000499",
        "text": "They did that by estimating the skills he learned.",
        "start": 2007720,
        "end": 2009560,
        "speaker": "A"
      },
      {
        "sid": "s000500",
        "text": "For those who haven't seen this movie, this is a guy who wakes up and lives the same day over and over again.",
        "start": 2009560,
        "end": 2013880,
        "speaker": "A"
      },
      {
        "sid": "s000501",
        "text": "And he goes through all the problems of, you know, selfish things first, then becoming sort of dissatisfied and trying to kill himself to get out of this loop.",
        "start": 2014280,
        "end": 2022500,
        "speaker": "A"
      },
      {
        "sid": "s000502",
        "text": "He realizes there's no way to break out of it, so he just Embraces it and starts doing good.",
        "start": 2022500,
        "end": 2026260,
        "speaker": "A"
      },
      {
        "sid": "s000503",
        "text": "So he saves his kid's life.",
        "start": 2026980,
        "end": 2028140,
        "speaker": "A"
      },
      {
        "sid": "s000504",
        "text": "He falls out of a tree.",
        "start": 2028140,
        "end": 2029100,
        "speaker": "A"
      },
      {
        "sid": "s000505",
        "text": "He helps somebody with their car.",
        "start": 2029100,
        "end": 2030980,
        "speaker": "A"
      },
      {
        "sid": "s000506",
        "text": "He knows what's going to happen, and he can plan it and basically perfect the day.",
        "start": 2031220,
        "end": 2035220,
        "speaker": "A"
      },
      {
        "sid": "s000507",
        "text": "I wish I had this uncertain day.",
        "start": 2035380,
        "end": 2037860,
        "speaker": "A"
      },
      {
        "sid": "s000508",
        "text": "But he's trained on one day.",
        "start": 2038740,
        "end": 2040340,
        "speaker": "A"
      },
      {
        "sid": "s000509",
        "text": "He is an expert on one day.",
        "start": 2040580,
        "end": 2042340,
        "speaker": "A"
      },
      {
        "sid": "s000510",
        "text": "So what happens on the very next day when he breaks out of the loop?",
        "start": 2042560,
        "end": 2046320,
        "speaker": "A"
      },
      {
        "sid": "s000511",
        "text": "Right.",
        "start": 2046480,
        "end": 2046800,
        "speaker": "A"
      },
      {
        "sid": "s000512",
        "text": "If your AI has been trained on one thing and one thing only, how is that going to help you the next day?",
        "start": 2046800,
        "end": 2051720,
        "speaker": "A"
      },
      {
        "sid": "s000513",
        "text": "This guy learned to play the piano.",
        "start": 2051720,
        "end": 2053000,
        "speaker": "A"
      },
      {
        "sid": "s000514",
        "text": "Okay?",
        "start": 2053000,
        "end": 2053240,
        "speaker": "A"
      },
      {
        "sid": "s000515",
        "text": "Granted, that will help him, but knowing what kid's going to fall out of a tree at what point in time only helps you on the day that it happens.",
        "start": 2053240,
        "end": 2058960,
        "speaker": "A"
      },
      {
        "sid": "s000516",
        "text": "So the idea.",
        "start": 2060000,
        "end": 2060800,
        "speaker": "A"
      },
      {
        "sid": "s000517",
        "text": "The idea is for training.",
        "start": 2062800,
        "end": 2064160,
        "speaker": "A"
      },
      {
        "sid": "s000518",
        "text": "What you try to do is have a training set that is comprehensive enough that you break into three pieces.",
        "start": 2065200,
        "end": 2070570,
        "speaker": "A"
      },
      {
        "sid": "s000519",
        "text": "You have a training set that you do to actually set the weights.",
        "start": 2070810,
        "end": 2074570,
        "speaker": "A"
      },
      {
        "sid": "s000520",
        "text": "You have a testing set that you evaluate, called the validation set, that evaluates how far you've come and how good your job you're doing.",
        "start": 2074810,
        "end": 2081690,
        "speaker": "A"
      },
      {
        "sid": "s000521",
        "text": "And then you have a completely separate test set that actually performs a test on the actual data.",
        "start": 2081770,
        "end": 2086330,
        "speaker": "A"
      },
      {
        "sid": "s000522",
        "text": "Was this tangent at y' all useful?",
        "start": 2090570,
        "end": 2092810,
        "speaker": "A"
      },
      {
        "sid": "s000523",
        "text": "I introduced another movie.",
        "start": 2095619,
        "end": 2096819,
        "speaker": "A"
      },
      {
        "sid": "s000524",
        "text": "Why does he keep talking about movies?",
        "start": 2097619,
        "end": 2099219,
        "speaker": "A"
      }
    ],
    "context_after_main_text": [
      {
        "sid": "s000525",
        "text": "All right, let's go back to ethics.",
        "start": 2099459,
        "end": 2106259,
        "speaker": "A"
      },
      {
        "sid": "s000526",
        "text": "So I took that tangent on just to refute your idea.",
        "start": 2107619,
        "end": 2111219,
        "speaker": "A"
      },
      {
        "sid": "s000527",
        "text": "That was pretty cool.",
        "start": 2111459,
        "end": 2112419,
        "speaker": "A"
      },
      {
        "sid": "s000528",
        "text": "So we were talking about d. Panicking.",
        "start": 2114179,
        "end": 2116659,
        "speaker": "A"
      },
      {
        "sid": "s000529",
        "text": "How many say panic?",
        "start": 2117939,
        "end": 2119139,
        "speaker": "A"
      },
      {
        "sid": "s000530",
        "text": "We're probably already at a point where it's too far.",
        "start": 2120670,
        "end": 2123150,
        "speaker": "A"
      },
      {
        "sid": "s000531",
        "text": "Anyone?",
        "start": 2123550,
        "end": 2124030,
        "speaker": "A"
      },
      {
        "sid": "s000532",
        "text": "No one's panicking.",
        "start": 2124030,
        "end": 2124870,
        "speaker": "A"
      },
      {
        "sid": "s000533",
        "text": "Okay, good.",
        "start": 2124870,
        "end": 2125350,
        "speaker": "A"
      },
      {
        "sid": "s000534",
        "text": "That's good.",
        "start": 2125350,
        "end": 2125950,
        "speaker": "A"
      }
    ]
  }
]