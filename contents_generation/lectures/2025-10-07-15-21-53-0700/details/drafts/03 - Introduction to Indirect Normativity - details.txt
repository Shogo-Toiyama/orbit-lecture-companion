# Introduction to Indirect Normativity

Indirect normativity is an alternative approach to instilling values in artificial intelligence, specifically when direct methods of uploading specific norms into a seed AI that develops into an Artificial Superintelligence (ASI) are not feasible. It proposes an indirect strategy when a direct, frontal approach to value alignment is impossible.

## What is Indirect Normativity?

**Indirect normativity** refers to an alternative method for guiding the values or norms of an artificial intelligence. It is presented as the necessary approach when it is not possible to directly upload specific norms or values into a **seed AI** that is intended to become an **Artificial Superintelligence (ASI)**. The core idea is that if a "direct assault" or "frontal assault" on value alignment is not viable, an indirect strategy must be employed.

## Why Indirect Normativity is Needed

The need for indirect normativity arises from the challenge of directly instilling specific values into an AI. The lecture highlights that if we cannot successfully upload specific norms directly into a seed AI that will evolve into an ASI, then an alternative is required. This implies that a direct method of value alignment is considered problematic or impossible, necessitating a different, indirect approach.

## Origin of the Concept

The idea of indirect normativity, as discussed in the lecture, is largely attributed to **Yudkowski**.

## Summary
*   **Indirect normativity** is an alternative strategy for guiding AI values.
*   It is necessary when directly uploading specific norms into a **seed AI** (which becomes an **ASI**) is not possible.
*   The concept suggests that if a "direct assault" on value alignment fails, an indirect method must be used.
*   This idea is largely derived from **Yudkowski**.