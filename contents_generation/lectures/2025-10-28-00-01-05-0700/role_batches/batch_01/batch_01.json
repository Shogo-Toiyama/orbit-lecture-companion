[
  {
    "context_before_main_text": [],
    "main_text": [
      {
        "sid": "s000001",
        "text": "I think the.",
        "start": 1760,
        "end": 2400,
        "speaker": "A"
      },
      {
        "sid": "s000002",
        "text": "One of the articles I had you all look at, someone tried to make an Avengers analog between those three different philosophies.",
        "start": 4240,
        "end": 10640,
        "speaker": "A"
      },
      {
        "sid": "s000003",
        "text": "So of the original primary kind of Avengers from the mcu, the ontological thinking, what do we think?",
        "start": 11200,
        "end": 20400,
        "speaker": "A"
      },
      {
        "sid": "s000004",
        "text": "Captain America thought, you know, kind of about morals, about doing the right thing, about making the right choices regardless of the outcome.",
        "start": 24160,
        "end": 31050,
        "speaker": "A"
      },
      {
        "sid": "s000005",
        "text": "Right.",
        "start": 31290,
        "end": 31690,
        "speaker": "A"
      },
      {
        "sid": "s000006",
        "text": "Utilitarian will be more what?",
        "start": 32810,
        "end": 34490,
        "speaker": "A"
      },
      {
        "sid": "s000007",
        "text": "That's true.",
        "start": 39690,
        "end": 40370,
        "speaker": "A"
      },
      {
        "sid": "s000008",
        "text": "So who.",
        "start": 40370,
        "end": 40770,
        "speaker": "A"
      },
      {
        "sid": "s000009",
        "text": "Which of the Avengers might be Iron Man?",
        "start": 40770,
        "end": 43930,
        "speaker": "A"
      },
      {
        "sid": "s000010",
        "text": "Iron Man.",
        "start": 43930,
        "end": 44570,
        "speaker": "A"
      },
      {
        "sid": "s000011",
        "text": "Iron man and virtue ethics, which I thought was kind of an interesting choice for this one, but who's got the old fashioned kind of virtue ethics appeal?",
        "start": 44970,
        "end": 53380,
        "speaker": "A"
      },
      {
        "sid": "s000012",
        "text": "I don't know.",
        "start": 60820,
        "end": 61380,
        "speaker": "A"
      },
      {
        "sid": "s000013",
        "text": "Thor maybe?",
        "start": 61380,
        "end": 62260,
        "speaker": "A"
      },
      {
        "sid": "s000014",
        "text": "All right, I'll have to see if that one makes sense.",
        "start": 62900,
        "end": 66260,
        "speaker": "A"
      },
      {
        "sid": "s000015",
        "text": "Maybe not, you know.",
        "start": 66500,
        "end": 67620,
        "speaker": "A"
      },
      {
        "sid": "s000016",
        "text": "Okay.",
        "start": 69300,
        "end": 69860,
        "speaker": "A"
      },
      {
        "sid": "s000017",
        "text": "All right, cool.",
        "start": 70900,
        "end": 71780,
        "speaker": "A"
      },
      {
        "sid": "s000018",
        "text": "So no questions about any of that.",
        "start": 72500,
        "end": 73940,
        "speaker": "A"
      },
      {
        "sid": "s000019",
        "text": "So these ethical frameworks, it's kind of interesting way to go into this philosophy kind of approach.",
        "start": 78830,
        "end": 84270,
        "speaker": "A"
      },
      {
        "sid": "s000020",
        "text": "How do we make decisions?",
        "start": 84910,
        "end": 86070,
        "speaker": "A"
      },
      {
        "sid": "s000021",
        "text": "How do we make choices?",
        "start": 86070,
        "end": 87150,
        "speaker": "A"
      },
      {
        "sid": "s000022",
        "text": "Most of us, when we look at, you know, a decision that we make every day, driving on the freeway or whatever, we don't tend to think about what's the impact going to be on everyone else.",
        "start": 87550,
        "end": 97150,
        "speaker": "A"
      },
      {
        "sid": "s000023",
        "text": "Calculus.",
        "start": 98270,
        "end": 98990,
        "speaker": "A"
      },
      {
        "sid": "s000024",
        "text": "Good and bad overall for a decision.",
        "start": 99230,
        "end": 101150,
        "speaker": "A"
      },
      {
        "sid": "s000025",
        "text": "We make choices in different ways.",
        "start": 103800,
        "end": 105320,
        "speaker": "A"
      },
      {
        "sid": "s000026",
        "text": "So I pulled these slides from.",
        "start": 105960,
        "end": 107880,
        "speaker": "A"
      },
      {
        "sid": "s000027",
        "text": "I updated the pictures because they had some other people in these pictures.",
        "start": 107960,
        "end": 110920,
        "speaker": "A"
      },
      {
        "sid": "s000028",
        "text": "I chose my own, but I pulled these slides from someone else's approach of how do we actually make choices as opposed to these philosophy kind of approaches to making decisions.",
        "start": 111160,
        "end": 121520,
        "speaker": "A"
      },
      {
        "sid": "s000029",
        "text": "And I want to kind of get your feel for what you tend to do in your own choices and how you make decisions.",
        "start": 121520,
        "end": 126840,
        "speaker": "A"
      },
      {
        "sid": "s000030",
        "text": "So one approach, and yes, I used Oppenheimer for this one, is because it just feels right, right.",
        "start": 127480,
        "end": 133900,
        "speaker": "A"
      },
      {
        "sid": "s000031",
        "text": "You have this gut feeling that something is the right idea.",
        "start": 133900,
        "end": 136380,
        "speaker": "A"
      },
      {
        "sid": "s000032",
        "text": "I like Oppenheimer's quote here.",
        "start": 136700,
        "end": 138460,
        "speaker": "A"
      },
      {
        "sid": "s000033",
        "text": "When you see something that is technically sweet, you go ahead and do it and you argue about what to do about it only after you've had your technical success.",
        "start": 138620,
        "end": 145580,
        "speaker": "A"
      },
      {
        "sid": "s000034",
        "text": "Wow.",
        "start": 146300,
        "end": 146740,
        "speaker": "A"
      },
      {
        "sid": "s000035",
        "text": "So much good and bad in that quote, right?",
        "start": 146740,
        "end": 148860,
        "speaker": "A"
      },
      {
        "sid": "s000036",
        "text": "Oprah has a better one.",
        "start": 149420,
        "end": 150700,
        "speaker": "A"
      },
      {
        "sid": "s000037",
        "text": "And then of course, you got Brad Pitts here, but lots of different approaches, but it's all based on this idea that you get a feeling that it's right, you just go for it.",
        "start": 151100,
        "end": 162230,
        "speaker": "A"
      },
      {
        "sid": "s000038",
        "text": "Listen to your conscience.",
        "start": 165590,
        "end": 166790,
        "speaker": "A"
      },
      {
        "sid": "s000039",
        "text": "I feel like this one is kind of overlapping in some way, but maybe not.",
        "start": 166790,
        "end": 170070,
        "speaker": "A"
      },
      {
        "sid": "s000040",
        "text": "We have to think about that.",
        "start": 170070,
        "end": 171110,
        "speaker": "A"
      },
      {
        "sid": "s000041",
        "text": "I don't think Oppenheimer is necessarily going with his conscience.",
        "start": 171430,
        "end": 174270,
        "speaker": "A"
      },
      {
        "sid": "s000042",
        "text": "He went with the scientific inspiration, the excellence of what he was fishing for.",
        "start": 174270,
        "end": 178550,
        "speaker": "A"
      },
      {
        "sid": "s000043",
        "text": "But Gandhi here is saying there's a Higher court in the courts of justice, and that is the court of conscience supersedes all other courts trying to make a right moral decision.",
        "start": 178710,
        "end": 187360,
        "speaker": "A"
      },
      {
        "sid": "s000044",
        "text": "What is correct?",
        "start": 187440,
        "end": 188240,
        "speaker": "A"
      },
      {
        "sid": "s000045",
        "text": "Mbappe, I think has a good quote here.",
        "start": 192960,
        "end": 195439,
        "speaker": "A"
      },
      {
        "sid": "s000046",
        "text": "Avoid mistakes by doing nothing.",
        "start": 195760,
        "end": 197600,
        "speaker": "A"
      },
      {
        "sid": "s000047",
        "text": "Right?",
        "start": 197600,
        "end": 197960,
        "speaker": "A"
      },
      {
        "sid": "s000048",
        "text": "You can't sit around and do nothing.",
        "start": 197960,
        "end": 200320,
        "speaker": "A"
      },
      {
        "sid": "s000049",
        "text": "You have to carry on.",
        "start": 200320,
        "end": 201520,
        "speaker": "A"
      },
      {
        "sid": "s000050",
        "text": "So inaction itself can be a choice.",
        "start": 202080,
        "end": 204850,
        "speaker": "A"
      },
      {
        "sid": "s000051",
        "text": "And so at least trying to do something, even if it's difficult to find that right.",
        "start": 205240,
        "end": 209960,
        "speaker": "A"
      },
      {
        "sid": "s000052",
        "text": "Optimization, you avoid the mistake of just being complacent.",
        "start": 209960,
        "end": 214120,
        "speaker": "A"
      },
      {
        "sid": "s000053",
        "text": "This is Indra Nui.",
        "start": 218600,
        "end": 219880,
        "speaker": "A"
      },
      {
        "sid": "s000054",
        "text": "So this is appealing to authority.",
        "start": 220120,
        "end": 222520,
        "speaker": "A"
      },
      {
        "sid": "s000055",
        "text": "Maybe I don't know the right decision, but someone else might be able to tell me.",
        "start": 223080,
        "end": 227640,
        "speaker": "A"
      },
      {
        "sid": "s000056",
        "text": "Leadership is hard to find good leadership, even if harder.",
        "start": 228360,
        "end": 230770,
        "speaker": "A"
      },
      {
        "sid": "s000057",
        "text": "But if you can get people to follow you to the ends of the earth, you are a great leader.",
        "start": 230770,
        "end": 233890,
        "speaker": "A"
      },
      {
        "sid": "s000058",
        "text": "Okay, so with these different types of approaches, what do you all think this?",
        "start": 235490,
        "end": 242530,
        "speaker": "A"
      },
      {
        "sid": "s000059",
        "text": "Is there anything other ways that you make decisions?",
        "start": 242610,
        "end": 245090,
        "speaker": "A"
      },
      {
        "sid": "s000060",
        "text": "What's easiest?",
        "start": 246289,
        "end": 247170,
        "speaker": "A"
      },
      {
        "sid": "s000061",
        "text": "Take the least amount of energy for me to do least amount of thinking.",
        "start": 249090,
        "end": 252690,
        "speaker": "A"
      },
      {
        "sid": "s000062",
        "text": "What else do these work with?",
        "start": 252690,
        "end": 257009,
        "speaker": "A"
      },
      {
        "sid": "s000063",
        "text": "Utilitarianism, the ontological thinking and virtue ethics?",
        "start": 257009,
        "end": 259849,
        "speaker": "A"
      },
      {
        "sid": "s000064",
        "text": "Or is this just.",
        "start": 259849,
        "end": 260529,
        "speaker": "A"
      },
      {
        "sid": "s000065",
        "text": "Are those just pipe dreams and this is how we really do them?",
        "start": 260529,
        "end": 264849,
        "speaker": "A"
      },
      {
        "sid": "s000066",
        "text": "Yeah, yeah, it works.",
        "start": 267169,
        "end": 276809,
        "speaker": "A"
      },
      {
        "sid": "s000067",
        "text": "It seems like it matches deontological thinking, but deontology may say that there's.",
        "start": 276809,
        "end": 281329,
        "speaker": "A"
      },
      {
        "sid": "s000068",
        "text": "I'm not making a choice on the moment.",
        "start": 282129,
        "end": 284100,
        "speaker": "A"
      },
      {
        "sid": "s000069",
        "text": "It's not a relativistic thing.",
        "start": 284100,
        "end": 285580,
        "speaker": "A"
      },
      {
        "sid": "s000070",
        "text": "Whereas the conscience might be more.",
        "start": 285580,
        "end": 287260,
        "speaker": "A"
      },
      {
        "sid": "s000071",
        "text": "Hey, in this moment, how do I feel about what I'm doing?",
        "start": 287740,
        "end": 290620,
        "speaker": "A"
      },
      {
        "sid": "s000072",
        "text": "Betraying my friend to the psychopathic murderer might mean that I'm keeping myself honest, but it doesn't feel good inside about me doing it.",
        "start": 291340,
        "end": 298620,
        "speaker": "A"
      },
      {
        "sid": "s000073",
        "text": "I'm sure Kant wouldn't say he felt good about making no choice.",
        "start": 298620,
        "end": 302460,
        "speaker": "A"
      },
      {
        "sid": "s000074",
        "text": "What are listening?",
        "start": 306140,
        "end": 307100,
        "speaker": "A"
      },
      {
        "sid": "s000075",
        "text": "Are these just completely different worlds or is it all part of a larger way that we can make decision processes?",
        "start": 312070,
        "end": 321910,
        "speaker": "A"
      },
      {
        "sid": "s000076",
        "text": "And in this class, if we think about something and it doesn't feel right like this, you see algorithmic bias and it feels wrong to your conscience.",
        "start": 322070,
        "end": 329550,
        "speaker": "A"
      },
      {
        "sid": "s000077",
        "text": "You can try to apply a framework for a more formal argument, but it may be that certain frameworks are of right and wrong at different points in time.",
        "start": 329550,
        "end": 336280,
        "speaker": "A"
      },
      {
        "sid": "s000078",
        "text": "I think that's the key.",
        "start": 336280,
        "end": 337240,
        "speaker": "A"
      },
      {
        "sid": "s000079",
        "text": "I think it's hard to be only one way about it.",
        "start": 337320,
        "end": 341000,
        "speaker": "A"
      },
      {
        "sid": "s000080",
        "text": "If you need to have sort of these different frameworks or different ways of exercising it when you find that middle ground.",
        "start": 341000,
        "end": 346840,
        "speaker": "A"
      },
      {
        "sid": "s000081",
        "text": "Okay, any other points?",
        "start": 350519,
        "end": 352280,
        "speaker": "A"
      },
      {
        "sid": "s000082",
        "text": "I'm surprised people didn't bring up one way that many people make decisions, and that's through emotions.",
        "start": 352760,
        "end": 358040,
        "speaker": "A"
      },
      {
        "sid": "s000083",
        "text": "I think emotions are often get a big push into our decision making.",
        "start": 359000,
        "end": 364520,
        "speaker": "A"
      },
      {
        "sid": "s000084",
        "text": "And in Terms of conscious and in terms of other things that might really influence how we launch the bigot.",
        "start": 364840,
        "end": 369520,
        "speaker": "A"
      },
      {
        "sid": "s000085",
        "text": "Yeah.",
        "start": 369520,
        "end": 369840,
        "speaker": "A"
      },
      {
        "sid": "s000086",
        "text": "How is that difference?",
        "start": 369840,
        "end": 370680,
        "speaker": "A"
      },
      {
        "sid": "s000087",
        "text": "How is the difference between it feels right and conscious or emotions?",
        "start": 370920,
        "end": 376600,
        "speaker": "A"
      },
      {
        "sid": "s000088",
        "text": "Yeah, emotions and it feels right.",
        "start": 376760,
        "end": 378600,
        "speaker": "A"
      },
      {
        "sid": "s000089",
        "text": "Yeah.",
        "start": 379320,
        "end": 379680,
        "speaker": "A"
      },
      {
        "sid": "s000090",
        "text": "I think if you are emotional about something and you're upset about something and you're heat of the moment, I think you're going with what feels emotionally right.",
        "start": 379680,
        "end": 390450,
        "speaker": "A"
      },
      {
        "sid": "s000091",
        "text": "But I think what Oppenheimer was describing was it felt right from a sense of I'm interested in this topic and it feels right for me to pursue it.",
        "start": 390690,
        "end": 399570,
        "speaker": "A"
      },
      {
        "sid": "s000092",
        "text": "And maybe I'm not thinking about the moral ramifications of what it might do in the world, but I'm thinking about, I really think this idea is cool and I want to go with it.",
        "start": 399650,
        "end": 407810,
        "speaker": "A"
      },
      {
        "sid": "s000093",
        "text": "I think that's different than I'm really pissed off that I'm going to do or I'm to really visceralize it.",
        "start": 408210,
        "end": 413700,
        "speaker": "A"
      },
      {
        "sid": "s000094",
        "text": "At least to me there's a difference.",
        "start": 413700,
        "end": 414860,
        "speaker": "A"
      },
      {
        "sid": "s000095",
        "text": "So what do you all think about implicit bias?",
        "start": 424860,
        "end": 428620,
        "speaker": "A"
      },
      {
        "sid": "s000096",
        "text": "This is something we're going to get into a little bit more when we have a whole topic on bias.",
        "start": 430540,
        "end": 434540,
        "speaker": "A"
      },
      {
        "sid": "s000097",
        "text": "But do you think that we have, have.",
        "start": 434860,
        "end": 437190,
        "speaker": "A"
      },
      {
        "sid": "s000098",
        "text": "Certainly biases in general can inform our decisions in terms of the decision making process.",
        "start": 437590,
        "end": 442790,
        "speaker": "A"
      },
      {
        "sid": "s000099",
        "text": "If we have a dislike of a certain thing, that would certainly play in.",
        "start": 443270,
        "end": 448110,
        "speaker": "A"
      },
      {
        "sid": "s000100",
        "text": "But what do you think about implicit biases?",
        "start": 448110,
        "end": 449910,
        "speaker": "A"
      },
      {
        "sid": "s000101",
        "text": "I took an implicit bias training class to be able to do certain things at this university.",
        "start": 450550,
        "end": 455510,
        "speaker": "A"
      },
      {
        "sid": "s000102",
        "text": "And you know, my first, some people in the class were pushing back a little bit that it's even possible to have implicit biases that you know how you feel about something.",
        "start": 456150,
        "end": 469540,
        "speaker": "A"
      },
      {
        "sid": "s000103",
        "text": "How would it be like sort of hidden.",
        "start": 469940,
        "end": 471620,
        "speaker": "A"
      },
      {
        "sid": "s000104",
        "text": "Maybe you hide it from everyone else, but you know, inside how you feel about a certain person.",
        "start": 471620,
        "end": 476180,
        "speaker": "A"
      },
      {
        "sid": "s000105",
        "text": "So do you think that there are implicit biases or not?",
        "start": 476500,
        "end": 478740,
        "speaker": "A"
      },
      {
        "sid": "s000106",
        "text": "Do you all know what implicit biases are?",
        "start": 483060,
        "end": 484660,
        "speaker": "A"
      },
      {
        "sid": "s000107",
        "text": "Let me show you a test that was done, an experiment that was done.",
        "start": 485060,
        "end": 487960,
        "speaker": "A"
      },
      {
        "sid": "s000108",
        "text": "So this one was a keyboard test that involved two different asks.",
        "start": 488830,
        "end": 494270,
        "speaker": "A"
      },
      {
        "sid": "s000109",
        "text": "This is a Harvard test called the implicit association test iat and what they did first was they asked users to look at different pictures of individuals and label them as black or white.",
        "start": 494350,
        "end": 506750,
        "speaker": "A"
      },
      {
        "sid": "s000110",
        "text": "And they would put the categorization by typing a key on the left of the keyboard and the right of the key.",
        "start": 507790,
        "end": 513730,
        "speaker": "A"
      },
      {
        "sid": "s000111",
        "text": "And the ask was sometimes they would ask to put white on one side like the left side.",
        "start": 514840,
        "end": 522000,
        "speaker": "A"
      },
      {
        "sid": "s000112",
        "text": "And sometimes they would ask for white to be on the other side.",
        "start": 522000,
        "end": 523880,
        "speaker": "A"
      },
      {
        "sid": "s000113",
        "text": "They would be switching where the individual was bucketized.",
        "start": 524040,
        "end": 526800,
        "speaker": "A"
      },
      {
        "sid": "s000114",
        "text": "Okay, so this is one test, you may say, if that itself is kind of an Odd test to do, but their idea was to then do something else.",
        "start": 526800,
        "end": 538360,
        "speaker": "A"
      },
      {
        "sid": "s000115",
        "text": "They had a separate test where they ask you when you see a word, if that word has a good association, you put it on one side.",
        "start": 538680,
        "end": 545530,
        "speaker": "A"
      },
      {
        "sid": "s000116",
        "text": "If that word has a bad association, you put it on the other side.",
        "start": 545610,
        "end": 548570,
        "speaker": "A"
      },
      {
        "sid": "s000117",
        "text": "And so maybe words like filth or sick or greed might go with your left hand, but words like beauty, joy, and happy go with your right hand.",
        "start": 548810,
        "end": 556330,
        "speaker": "A"
      },
      {
        "sid": "s000118",
        "text": "So again, it's a bucketization task where you're being asked to assess things that are coming on the screen and put it in the right bucket.",
        "start": 556970,
        "end": 565030,
        "speaker": "A"
      },
      {
        "sid": "s000119",
        "text": "So what they varied for this test was whether they lined up white with good or black with good.",
        "start": 568620,
        "end": 575660,
        "speaker": "A"
      },
      {
        "sid": "s000120",
        "text": "And what I mean by good is that the bucket's on the same side.",
        "start": 575740,
        "end": 579100,
        "speaker": "A"
      },
      {
        "sid": "s000121",
        "text": "They would never mix it so that you were dealing with, you know, both at the same time on the screen.",
        "start": 579660,
        "end": 585500,
        "speaker": "A"
      },
      {
        "sid": "s000122",
        "text": "But the ask of where you're bucket sizing was based on either they're both left or both right.",
        "start": 585900,
        "end": 593790,
        "speaker": "A"
      },
      {
        "sid": "s000123",
        "text": "Does that make sense?",
        "start": 593790,
        "end": 594550,
        "speaker": "A"
      },
      {
        "sid": "s000124",
        "text": "So this gap here in time, this is based on the amount of time it took to do this test.",
        "start": 595830,
        "end": 599830,
        "speaker": "A"
      },
      {
        "sid": "s000125",
        "text": "It found that there was a significant difference in how people that were taking this test perceived the combination of the two, how easy it was for them to do this exercise when they paired white with good versus black with good.",
        "start": 600470,
        "end": 614550,
        "speaker": "A"
      },
      {
        "sid": "s000126",
        "text": "This is one indication of an implicit bias.",
        "start": 615110,
        "end": 617360,
        "speaker": "A"
      },
      {
        "sid": "s000127",
        "text": "Does that make sense?",
        "start": 618320,
        "end": 619200,
        "speaker": "A"
      },
      {
        "sid": "s000128",
        "text": "Any questions about this, guys?",
        "start": 619520,
        "end": 620800,
        "speaker": "A"
      },
      {
        "sid": "s000129",
        "text": "So, like I said, we'll talk more about this when it comes to AI and what it means for our algorithms to have an implicit bias, whether based on data that it's getting from us or our own assumptions into the internal.",
        "start": 626160,
        "end": 637840,
        "speaker": "A"
      },
      {
        "sid": "s000130",
        "text": "All right, so computing, when we're talking about how to make decisions and how to come up with ideas or ethical quandaries or avoid biases and that sort of thing.",
        "start": 640240,
        "end": 651210,
        "speaker": "A"
      },
      {
        "sid": "s000131",
        "text": "For computing, there are three things that make it unique, more challenging than most of the areas that we deal with.",
        "start": 651210,
        "end": 656730,
        "speaker": "A"
      },
      {
        "sid": "s000132",
        "text": "One of them is reproducibility.",
        "start": 657130,
        "end": 658650,
        "speaker": "A"
      },
      {
        "sid": "s000133",
        "text": "We have a tremendous amount of data that is being provided, both created, exchanged, reproduced, and being able to handle that and see all these different situations come up makes it very difficult to kind of replicate decisions or understand decisions.",
        "start": 660250,
        "end": 677460,
        "speaker": "A"
      },
      {
        "sid": "s000134",
        "text": "But we do have this ability to preserve all these records, all this data, and try to do something meaningful.",
        "start": 678340,
        "end": 684420,
        "speaker": "A"
      },
      {
        "sid": "s000135",
        "text": "The second thing is information flow.",
        "start": 685860,
        "end": 687620,
        "speaker": "A"
      },
      {
        "sid": "s000136",
        "text": "The communication is not only like different people's talking at once, but also this one to many, where an individual is receiving a lot of bombardment and then identity conditions, because we're anonymous in online activities, but not always anonymous in person activities because of being recorded and monitored, space recognition and everything Else it creates a weird dichotomy of when your identity is preserved and when it's not.",
        "start": 688500,
        "end": 715150,
        "speaker": "A"
      },
      {
        "sid": "s000137",
        "text": "All right, I want to jump in on something you may have seen already, but I think, to me, at least, it's an interesting exercise for talking about a computing idea that has a really interesting ethical quandary and it's also based on something you would see in a real.",
        "start": 716190,
        "end": 733870,
        "speaker": "A"
      },
      {
        "sid": "s000138",
        "text": "How many of you already know the Charlie crop?",
        "start": 735390,
        "end": 737150,
        "speaker": "A"
      },
      {
        "sid": "s000139",
        "text": "So there's many different variants of the Charlie crop, but the basic idea is that there's a trolley going out of control.",
        "start": 739390,
        "end": 746130,
        "speaker": "A"
      },
      {
        "sid": "s000140",
        "text": "It's going to mow down five people who are just sitting there like they wanted to be hit.",
        "start": 746690,
        "end": 750130,
        "speaker": "A"
      },
      {
        "sid": "s000141",
        "text": "And then there's a track switch in front of you that you can push and switch to kill only one person instead.",
        "start": 750530,
        "end": 757010,
        "speaker": "A"
      },
      {
        "sid": "s000142",
        "text": "Grave analogy.",
        "start": 757730,
        "end": 758770,
        "speaker": "A"
      },
      {
        "sid": "s000143",
        "text": "So your decision in this particular case is, do you stop the trolley or not?",
        "start": 759810,
        "end": 766050,
        "speaker": "A"
      },
      {
        "sid": "s000144",
        "text": "Sorry, that would be greater.",
        "start": 766530,
        "end": 768290,
        "speaker": "A"
      },
      {
        "sid": "s000145",
        "text": "Do you squeeze the track or not to be able to change the direction the trolley is going.",
        "start": 768690,
        "end": 772680,
        "speaker": "A"
      },
      {
        "sid": "s000146",
        "text": "Right.",
        "start": 772840,
        "end": 773240,
        "speaker": "A"
      },
      {
        "sid": "s000147",
        "text": "Pretend that you don't have some kind of strength, stuff trolley in another way.",
        "start": 773800,
        "end": 778040,
        "speaker": "A"
      },
      {
        "sid": "s000148",
        "text": "So just out of curiosity, how many would choose a. I'm going to pull the switch and I might kill one person, but I would say five.",
        "start": 778840,
        "end": 789480,
        "speaker": "A"
      },
      {
        "sid": "s000149",
        "text": "It's a very.",
        "start": 791720,
        "end": 792400,
        "speaker": "A"
      },
      {
        "sid": "s000150",
        "text": "What.",
        "start": 792400,
        "end": 792720,
        "speaker": "A"
      },
      {
        "sid": "s000151",
        "text": "What kind of argument would you say that is very utilitarian.",
        "start": 792720,
        "end": 797650,
        "speaker": "A"
      },
      {
        "sid": "s000152",
        "text": "Unless that maybe you really didn't like that one person and you had a deontological thinking of vengeance or something like that.",
        "start": 797650,
        "end": 803010,
        "speaker": "A"
      },
      {
        "sid": "s000153",
        "text": "But assuming that you didn't know anyone here, that would be a very utilitarian solution to the problem.",
        "start": 803490,
        "end": 807810,
        "speaker": "A"
      },
      {
        "sid": "s000154",
        "text": "One life unfortunately expired and everyone who loves that person but you saved the pot, how many would refuse to touch the switch?",
        "start": 808290,
        "end": 815970,
        "speaker": "A"
      },
      {
        "sid": "s000155",
        "text": "Look, people are gonna die.",
        "start": 815970,
        "end": 817170,
        "speaker": "A"
      },
      {
        "sid": "s000156",
        "text": "Wasn't my fault.",
        "start": 817170,
        "end": 818050,
        "speaker": "A"
      },
      {
        "sid": "s000157",
        "text": "Blame the trolley manufacturer.",
        "start": 818690,
        "end": 820690,
        "speaker": "A"
      },
      {
        "sid": "s000158",
        "text": "Okay, so why not?",
        "start": 822140,
        "end": 824140,
        "speaker": "A"
      },
      {
        "sid": "s000159",
        "text": "I mean, you could say beyond the logical thinking.",
        "start": 825420,
        "end": 827580,
        "speaker": "A"
      },
      {
        "sid": "s000160",
        "text": "Right?",
        "start": 827580,
        "end": 827900,
        "speaker": "A"
      },
      {
        "sid": "s000161",
        "text": "I don't want to kill someone.",
        "start": 828300,
        "end": 829580,
        "speaker": "A"
      },
      {
        "sid": "s000162",
        "text": "It's not my choice.",
        "start": 830060,
        "end": 831100,
        "speaker": "A"
      },
      {
        "sid": "s000163",
        "text": "When I touch that switch, I'm making a choice.",
        "start": 831100,
        "end": 833660,
        "speaker": "A"
      },
      {
        "sid": "s000164",
        "text": "Right.",
        "start": 833740,
        "end": 834140,
        "speaker": "A"
      },
      {
        "sid": "s000165",
        "text": "Mbappe would disagree.",
        "start": 834460,
        "end": 835580,
        "speaker": "A"
      },
      {
        "sid": "s000166",
        "text": "He would say you're refusing to act and that kind of thing.",
        "start": 835580,
        "end": 837339,
        "speaker": "A"
      },
      {
        "sid": "s000167",
        "text": "But let's just, you know, that's one approach.",
        "start": 837339,
        "end": 839660,
        "speaker": "A"
      },
      {
        "sid": "s000168",
        "text": "Some of you didn't raise your hand.",
        "start": 840700,
        "end": 841820,
        "speaker": "A"
      },
      {
        "sid": "s000169",
        "text": "Is there another alternative?",
        "start": 841820,
        "end": 842900,
        "speaker": "A"
      },
      {
        "sid": "s000170",
        "text": "Do you have a creative Kobayashi Maru solution here to the, to the trolley problem?",
        "start": 842900,
        "end": 847910,
        "speaker": "A"
      },
      {
        "sid": "s000171",
        "text": "Yes.",
        "start": 848790,
        "end": 849270,
        "speaker": "A"
      },
      {
        "sid": "s000172",
        "text": "Panic.",
        "start": 850150,
        "end": 850790,
        "speaker": "A"
      },
      {
        "sid": "s000173",
        "text": "The scream?",
        "start": 851110,
        "end": 851990,
        "speaker": "A"
      },
      {
        "sid": "s000174",
        "text": "Yes.",
        "start": 852710,
        "end": 853190,
        "speaker": "A"
      },
      {
        "sid": "s000175",
        "text": "Any other solutions other than panic?",
        "start": 856470,
        "end": 858710,
        "speaker": "A"
      },
      {
        "sid": "s000176",
        "text": "Yes, I think, like, it would depend, like, like, depending on who the person, like, who the people are.",
        "start": 859510,
        "end": 864750,
        "speaker": "B"
      },
      {
        "sid": "s000177",
        "text": "Like, some people might be, like, more inclined to save the, like, one person instead of like, five.",
        "start": 864750,
        "end": 868590,
        "speaker": "B"
      },
      {
        "sid": "s000178",
        "text": "Like, especially if, like, persons, like, they love them or something, like have some kind of relationship it might, like, influence their thinking.",
        "start": 868590,
        "end": 874600,
        "speaker": "B"
      },
      {
        "sid": "s000179",
        "text": "So I don't know, like, if there's a good answer.",
        "start": 874600,
        "end": 876400,
        "speaker": "B"
      },
      {
        "sid": "s000180",
        "text": "So that's how you make the trolley problem more interesting.",
        "start": 876640,
        "end": 879200,
        "speaker": "A"
      },
      {
        "sid": "s000181",
        "text": "Right?",
        "start": 879200,
        "end": 879480,
        "speaker": "A"
      },
      {
        "sid": "s000182",
        "text": "And there's other variants as well, where you could push someone off of a bridge and the person is able to stop the trolley.",
        "start": 879480,
        "end": 888240,
        "speaker": "A"
      },
      {
        "sid": "s000183",
        "text": "And so you, instead of just throwing a switch, you know, you could get the variant where you actively are killing someone to make the trolley stop.",
        "start": 888320,
        "end": 895120,
        "speaker": "A"
      },
      {
        "sid": "s000184",
        "text": "It's a lot more personal.",
        "start": 895520,
        "end": 896560,
        "speaker": "A"
      },
      {
        "sid": "s000185",
        "text": "Or, you know, what if you knew the people?",
        "start": 896880,
        "end": 898490,
        "speaker": "A"
      },
      {
        "sid": "s000186",
        "text": "What if it was someone who was a quote, unquote, more productive member of society versus not it was one.",
        "start": 898490,
        "end": 903010,
        "speaker": "A"
      },
      {
        "sid": "s000187",
        "text": "Einstein versus, you know, five.",
        "start": 903010,
        "end": 904770,
        "speaker": "A"
      },
      {
        "sid": "s000188",
        "text": "Something else.",
        "start": 904770,
        "end": 905450,
        "speaker": "A"
      },
      {
        "sid": "s000189",
        "text": "That's another variant of the trolley problem.",
        "start": 906730,
        "end": 908810,
        "speaker": "A"
      },
      {
        "sid": "s000190",
        "text": "Right?",
        "start": 908810,
        "end": 909210,
        "speaker": "A"
      },
      {
        "sid": "s000191",
        "text": "I liked.",
        "start": 912250,
        "end": 912970,
        "speaker": "A"
      },
      {
        "sid": "s000192",
        "text": "This is a recent quote from Desi Lydic.",
        "start": 913290,
        "end": 915210,
        "speaker": "A"
      },
      {
        "sid": "s000193",
        "text": "Trolley problem is the problem that you only have one problem.",
        "start": 915290,
        "end": 917490,
        "speaker": "A"
      },
      {
        "sid": "s000194",
        "text": "Okay?",
        "start": 917490,
        "end": 918010,
        "speaker": "A"
      },
      {
        "sid": "s000195",
        "text": "Anyway, let's modernize this problem.",
        "start": 919130,
        "end": 921770,
        "speaker": "A"
      },
      {
        "sid": "s000196",
        "text": "So autonomous vehicles.",
        "start": 922650,
        "end": 925540,
        "speaker": "A"
      },
      {
        "sid": "s000197",
        "text": "Okay, many of you may have seen this already, but this has been the kind of modern trolley problem.",
        "start": 925780,
        "end": 930580,
        "speaker": "A"
      },
      {
        "sid": "s000198",
        "text": "Autonomous vehicles.",
        "start": 930820,
        "end": 931940,
        "speaker": "A"
      },
      {
        "sid": "s000199",
        "text": "The idea being that we're doing all these beautiful things, making our roads safer, protecting the environment by having fewer cars, or making the cars more efficiently, better accessibility for those who need it.",
        "start": 931940,
        "end": 942500,
        "speaker": "A"
      },
      {
        "sid": "s000200",
        "text": "The job part is a question mark.",
        "start": 942820,
        "end": 944900,
        "speaker": "A"
      },
      {
        "sid": "s000201",
        "text": "But economic growth could be.",
        "start": 945300,
        "end": 946620,
        "speaker": "A"
      },
      {
        "sid": "s000202",
        "text": "And there's all kinds of other issues that come with autonomous vehicles that we'll talk about.",
        "start": 946620,
        "end": 950860,
        "speaker": "A"
      },
      {
        "sid": "s000203",
        "text": "Problematic.",
        "start": 952060,
        "end": 952780,
        "speaker": "A"
      },
      {
        "sid": "s000204",
        "text": "But let's just take a look for a second at the difference morally between a human driver and an autonomous vehicle.",
        "start": 952780,
        "end": 959820,
        "speaker": "A"
      },
      {
        "sid": "s000205",
        "text": "If you are a human driver and you make a decision that's split second and you have an accident or something happens, usually not premeditated.",
        "start": 960380,
        "end": 969740,
        "speaker": "A"
      },
      {
        "sid": "s000206",
        "text": "I know we can come up with examples earlier, but it's usually not premeditated.",
        "start": 970060,
        "end": 973940,
        "speaker": "A"
      },
      {
        "sid": "s000207",
        "text": "But an autonomous vehicle, if it was engineered ahead of time and if it was following standards where they have certain types of scenarios, they want to see how the car performs.",
        "start": 973940,
        "end": 982840,
        "speaker": "A"
      },
      {
        "sid": "s000208",
        "text": "They are programming in, or at least learning in some way through scenarios that are real.",
        "start": 983240,
        "end": 989400,
        "speaker": "A"
      },
      {
        "sid": "s000209",
        "text": "And so is there a difference in legality for what they are morally held by?",
        "start": 989560,
        "end": 996040,
        "speaker": "A"
      },
      {
        "sid": "s000210",
        "text": "If their code or learning patterns or test patterns include something that actually occurs and makes a choice that is questionable, everybody see the difference?",
        "start": 996120,
        "end": 1005010,
        "speaker": "A"
      },
      {
        "sid": "s000211",
        "text": "So MIT had this project called the Moral Machine, and they had this on their website.",
        "start": 1007730,
        "end": 1013410,
        "speaker": "A"
      },
      {
        "sid": "s000212",
        "text": "I think it might.",
        "start": 1013410,
        "end": 1013930,
        "speaker": "A"
      },
      {
        "sid": "s000213",
        "text": "I don't know if it's still there or not, but it was basically a set of questions like the trolley problem, where they would show a scenario and say, here's a car, autonomous vehicle, it can't stop, I don't know why, it breaks her out.",
        "start": 1013930,
        "end": 1026370,
        "speaker": "A"
      },
      {
        "sid": "s000214",
        "text": "And it can either plow into five pedestrians or one and swerve out of the way.",
        "start": 1027140,
        "end": 1032500,
        "speaker": "A"
      },
      {
        "sid": "s000215",
        "text": "Kind of like the trolley problem.",
        "start": 1033140,
        "end": 1034580,
        "speaker": "A"
      },
      {
        "sid": "s000216",
        "text": "Right.",
        "start": 1034740,
        "end": 1035140,
        "speaker": "A"
      },
      {
        "sid": "s000217",
        "text": "So what should it do?",
        "start": 1035620,
        "end": 1036620,
        "speaker": "A"
      },
      {
        "sid": "s000218",
        "text": "And the difference here is that you're dealing with a car where you're programming it ahead of time.",
        "start": 1036620,
        "end": 1042180,
        "speaker": "A"
      },
      {
        "sid": "s000219",
        "text": "This is not.",
        "start": 1042580,
        "end": 1043380,
        "speaker": "A"
      },
      {
        "sid": "s000220",
        "text": "Oh, my God, my brakes don't work.",
        "start": 1043460,
        "end": 1044980,
        "speaker": "A"
      },
      {
        "sid": "s000221",
        "text": "What do I do?",
        "start": 1044980,
        "end": 1045860,
        "speaker": "A"
      },
      {
        "sid": "s000222",
        "text": "And maybe I'm not accountable for it.",
        "start": 1046180,
        "end": 1048180,
        "speaker": "A"
      },
      {
        "sid": "s000223",
        "text": "So they camp with all different variants.",
        "start": 1049380,
        "end": 1051940,
        "speaker": "A"
      },
      {
        "sid": "s000224",
        "text": "This is not my.",
        "start": 1052110,
        "end": 1052830,
        "speaker": "A"
      },
      {
        "sid": "s000225",
        "text": "This is not mine.",
        "start": 1053470,
        "end": 1054430,
        "speaker": "A"
      },
      {
        "sid": "s000226",
        "text": "This is theirs.",
        "start": 1054670,
        "end": 1055630,
        "speaker": "A"
      },
      {
        "sid": "s000227",
        "text": "They said, what if it was two elderly people, two young people and a cat versus five people who just robbed the bank and are carrying a bag of money?",
        "start": 1055870,
        "end": 1063710,
        "speaker": "A"
      },
      {
        "sid": "s000228",
        "text": "Which should the car pick does that influence?",
        "start": 1065710,
        "end": 1067630,
        "speaker": "A"
      },
      {
        "sid": "s000229",
        "text": "They had all kinds of scenarios and all kinds of ways for people to think about.",
        "start": 1068430,
        "end": 1073470,
        "speaker": "A"
      },
      {
        "sid": "s000230",
        "text": "How would they weigh one life or another?",
        "start": 1073710,
        "end": 1075630,
        "speaker": "A"
      },
      {
        "sid": "s000231",
        "text": "Not actually a fan of how they did this necessarily, but it raises an interesting issue that I want to take into a different scenario.",
        "start": 1077720,
        "end": 1083400,
        "speaker": "A"
      },
      {
        "sid": "s000232",
        "text": "Here's my scenario.",
        "start": 1084760,
        "end": 1085880,
        "speaker": "A"
      },
      {
        "sid": "s000233",
        "text": "Let's suppose you are designing an autonomous vehicle and you have a scenario that you are testing.",
        "start": 1086600,
        "end": 1092520,
        "speaker": "A"
      },
      {
        "sid": "s000234",
        "text": "The scenario is the car is behind a big truck full of logs.",
        "start": 1092840,
        "end": 1098280,
        "speaker": "A"
      },
      {
        "sid": "s000235",
        "text": "The logs come off and are clearly going to damage the car, maybe kill everyone inside.",
        "start": 1099160,
        "end": 1103810,
        "speaker": "A"
      },
      {
        "sid": "s000236",
        "text": "If you plow into the logs and you have to go left or right.",
        "start": 1103810,
        "end": 1107330,
        "speaker": "A"
      },
      {
        "sid": "s000237",
        "text": "Okay, Braking in time is not going to help.",
        "start": 1107570,
        "end": 1109650,
        "speaker": "A"
      }
    ],
    "context_after_main_text": [
      {
        "sid": "s000238",
        "text": "You've got a motorcyclist wearing a helmet to the right and an suv, lots of safety features, full of people to the left.",
        "start": 1110930,
        "end": 1117650,
        "speaker": "A"
      },
      {
        "sid": "s000239",
        "text": "Which way do you go?",
        "start": 1118210,
        "end": 1119330,
        "speaker": "A"
      },
      {
        "sid": "s000240",
        "text": "Do you crash into the SUV or you crash into the motorcycle?",
        "start": 1119490,
        "end": 1121970,
        "speaker": "A"
      },
      {
        "sid": "s000241",
        "text": "What do you think?",
        "start": 1123410,
        "end": 1124130,
        "speaker": "A"
      },
      {
        "sid": "s000242",
        "text": "Kind of horrible thought, but I'm asking.",
        "start": 1127810,
        "end": 1130970,
        "speaker": "A"
      },
      {
        "sid": "s000243",
        "text": "Yeah, I mean, maybe it depends on.",
        "start": 1130970,
        "end": 1133450,
        "speaker": "B"
      },
      {
        "sid": "s000244",
        "text": "The number of passengers in the car.",
        "start": 1133450,
        "end": 1135050,
        "speaker": "A"
      },
      {
        "sid": "s000245",
        "text": "Okay, let's say that the yellow car has four passengers and the SUV has five, and the motorcyclist is just a solo.",
        "start": 1135130,
        "end": 1144250,
        "speaker": "A"
      },
      {
        "sid": "s000246",
        "text": "What would that be?",
        "start": 1144810,
        "end": 1145610,
        "speaker": "A"
      },
      {
        "sid": "s000247",
        "text": "I think a motorcycle.",
        "start": 1146250,
        "end": 1147450,
        "speaker": "A"
      }
    ]
  }
]