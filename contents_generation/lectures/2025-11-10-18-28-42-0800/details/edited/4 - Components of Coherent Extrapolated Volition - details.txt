# 4. Components of Coherent Extrapolated Volition

Coherent Extrapolated Volition (CEV) is an indirect method for instilling human values into an Artificial Superintelligence (ASI), proposed as an alternative to the impossible task of directly uploading specific values ‚ü¶s000029 (noted elsewhere in the lecture), s000053 (noted elsewhere in the lecture), s000072 (noted elsewhere in the lecture)‚üß. It involves the ASI extrapolating a generalized understanding of human values from a broad baseline of ethical systems and then coherently applying them ‚ü¶s000057, s000061, s000082‚üß.

## ‚ùì Why an Indirect Approach to ASI Values is Necessary

The development of Artificial Superintelligence (ASI) necessitates ensuring it is *trustworthy* and *safe* ‚ü¶s000004 (noted elsewhere in the lecture)‚üß.
This means it will not harm human beings or lead to their extinction ‚ü¶s000005 (noted elsewhere in the lecture), s000010 (noted elsewhere in the lecture), s000072‚üß.
Previous attempts to directly upload specific human values into a seed AI, which would then become an ASI, have been deemed impossible or unsafe ‚ü¶s000015 (noted elsewhere in the lecture), s000018 (noted elsewhere in the lecture), s000053 (noted elsewhere in the lecture), s000072‚üß.
This impossibility stems from two main issues.
First, humans cannot definitively decide what those specific values ought to be ‚ü¶s000054 (noted elsewhere in the lecture)‚üß.
Second, even if known, it would be extremely difficult to translate them into computer language ‚ü¶s000055 (noted elsewhere in the lecture)‚üß.
Therefore, an *indirect normativity* approach, such as Coherent Extrapolated Volition (CEV), is proposed.
This is a feasible alternative to inform the ASI about human values ‚ü¶s000029 (noted elsewhere in the lecture), s000030 (noted elsewhere in the lecture), s000072, s000073‚üß.

## üí° The Concept of Extrapolated Volition

The "extrapolated" component of CEV involves giving the computer a general idea of what human values look like ‚ü¶s000058, s000060‚üß.
This is achieved by examining a wide variety of existing ethical systems and ways of thinking about norms, which form a "baseline" ‚ü¶s000056, s000061, s000068‚üß.
The lecture poses the question, "Well, whose human values?" when discussing this baseline ‚ü¶s000059‚üß.
From this comprehensive baseline, the ASI is meant to extrapolate an abstract generality of human values ‚ü¶s000061‚üß.
This process is likened to putting human values in an envelope and asking the ASI to "guess what's there," rather than explicitly stating them ‚ü¶s000063‚üß.

## ü§ù The Concept of Coherent Volition

The "coherence" aspect of CEV refers to the process of bringing together these diverse ethical perspectives and extrapolated human values in an abstract way ‚ü¶s000082‚üß.
This abstract understanding then provides the computer with a fundamental basis for making specific decisions in the future ‚ü¶s000082‚üß.

## ü§ñ ASI's Role and the Heuristic Principle

A key advantage of CEV is that it offloads most of the work of understanding and applying values to the ASI itself ‚ü¶s000057‚üß.
The *heuristic principle* of CEV dictates that humans defer to the ASI regarding how to apply specific instantiations of these generalized human values ‚ü¶s000064, s000065, s000067‚üß.
The lecture notes that the heuristic principle means "we're going to try it out" ‚ü¶s000066‚üß.
This approach aims to keep human beings "in the loop" for value alignment without requiring them to perform the impossible task of directly uploading specific values ‚ü¶s000052 (noted elsewhere in the lecture), s000053 (noted elsewhere in the lecture)‚üß.

## ü§î Yudkowski's "What We Would Wish" Principle

The core idea of CEV, as articulated by Yudkowski, is to determine "what we would wish were we to know what we really want" ‚ü¶s000074, s000076‚üß.
This implies considering what humans would desire if they were brighter, had more time to think, and were capable of thinking *convergently* ‚ü¶s000077‚üß.
Convergent thinking means being inclusive of many different ways of thinking about values ‚ü¶s000078‚üß.
This is in contrast to thinking *divergently* with individual sets of values, such as "my set of values, your set of values" ‚ü¶s000078, s000079‚üß.
Instead, it focuses on what it means to be human and to have human values ‚ü¶s000080, s000081‚üß.

## ‚úÖ CEV's Advantage Over Direct Rules

CEV is considered more tractable than implementing specific rules ‚ü¶s000087 (noted elsewhere in the lecture)‚üß.
Rules are prone to misinterpretation and are not how human beings typically operate ‚ü¶s000088 (noted elsewhere in the lecture), s000091 (noted elsewhere in the lecture), s000092 (noted elsewhere in the lecture), s000101 (noted elsewhere in the lecture), s000102 (noted elsewhere in the lecture), s000106 (noted elsewhere in the lecture)‚üß.
Unlike rigid rules, CEV is *open-ended* and abstract ‚ü¶s000094 (noted elsewhere in the lecture)‚üß.
This allows the ASI to invent its own "rules" or specific decisions based on the underlying "thought" or meaning ‚ü¶s000096 (noted elsewhere in the lecture), s000098 (noted elsewhere in the lecture), s000099 (noted elsewhere in the lecture), s000100 (noted elsewhere in the lecture)‚üß.
This aligns with the idea of "do as I mean, not as I say," where the system understands the intent behind values rather than just following explicit instructions ‚ü¶s000112 (noted elsewhere in the lecture), s000113 (noted elsewhere in the lecture), s000118 (noted elsewhere in the lecture), s000122 (noted elsewhere in the lecture)‚üß.
Experience in AI research, such as the "bitter lesson of AI," suggests that putting human knowledge or rules directly into systems does not work ‚ü¶s000126 (noted elsewhere in the lecture), s000127 (noted elsewhere in the lecture)‚üß.
Instead, building general learning systems that can learn for themselves from data is more effective ‚ü¶s000128 (noted elsewhere in the lecture), s000133 (noted elsewhere in the lecture), s000134 (noted elsewhere in the lecture), s000136 (noted elsewhere in the lecture)‚üß.

## ‚ö†Ô∏è Challenges in Defining the Baseline

A significant difficulty with the CEV baseline is determining who or what gets included in the collection of ethical systems from which values are extrapolated ‚ü¶s000069‚üß.
The lecture acknowledges that there are problems associated with CEV ‚ü¶s000071‚üß.