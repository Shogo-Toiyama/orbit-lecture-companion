# 1. The Challenge of Friendly ASI

This topic explores the critical need to ensure Artificial Superintelligence (ASI) is trustworthy and safe for humanity ‚ü¶s000004‚üß. The primary challenge lies in the difficulty of directly instilling human values into ASI ‚ü¶s000015, s000018, s000053, s000054, s000055 (noted elsewhere in the lecture)‚üß. This necessitates exploring alternative, indirect methods to prevent potential harm or even extinction ‚ü¶s000010, s000017, s000018, s000026, s000028, s000052, s000053, s000072, s000073 (noted elsewhere in the lecture)‚üß.

## ü§ù Defining Friendly ASI and Its Importance

As humanity progresses towards Artificial Superintelligence (ASI), there is a significant concern that ASI must be trustworthy and safe ‚ü¶s000004‚üß.
This concept of trustworthiness and safety is encapsulated by the term **"friendly" ASI** ‚ü¶s000005‚üß.
The term "friendly AI" was coined by Eleazar Yudkowski, whose work is referenced by Bostrom in this context ‚ü¶s000006, s000007‚üß.
It is important to clarify that "friendly" does not imply an anthropomorphic sense of coziness or social interaction, such as an ASI asking to go out for a beer ‚ü¶s000008, s000009‚üß.
Instead, **friendly ASI** means that the system will not harm human beings ‚ü¶s000010‚üß.
Critically, it will not lead to the extinction of humanity ‚ü¶s000010‚üß.
This potential for harm, primarily through inadvertent actions rather than malice, is seen as a genuine possibility by those concerned with ASI development ‚ü¶s000010‚üß.

## üö® The Urgent Concern for ASI Safety

Many individuals concerned about the ongoing development of artificial intelligence emphasize the immediate need to address the safety and trustworthiness of ASI ‚ü¶s000004‚üß.
The core objective is to prevent the ASI from acting in ways that could be detrimental to human beings ‚ü¶s000010‚üß.
If a reliable method for ensuring ASI friendliness cannot be found, the development of such advanced AI might need to be halted due to its inherent dangers ‚ü¶s000022, s000023, s000024 (noted elsewhere in the lecture)‚üß.

## üöß Difficulties in Directly Uploading Values to ASI

A significant challenge in achieving friendly ASI stems from the difficulty of directly embedding human values into these systems ‚ü¶s000015, s000018 (noted elsewhere in the lecture)‚üß.
Previous attempts or assumptions involved trying to upload specific values into the "seed computer" that would evolve into an ASI ‚ü¶s000015, s000026 (noted elsewhere in the lecture)‚üß.
However, this approach faces two major hurdles:
*   **Determining Universal Values:** It is challenging for humans to collectively decide what specific values ought to be uploaded.
*   **Translating Values into Code:** Even if values were agreed upon, it would be extremely difficult to translate complex human values into computer language that the ASI could understand and implement.
‚ü¶s000054, s000055 (noted elsewhere in the lecture)‚üß
Methods like reinforcement learning and scaffolding have been explored, but they have not been shown to work effectively for directly uploading values ‚ü¶s000019 (noted elsewhere in the lecture)‚üß.
The conclusion from prior discussions is that there is currently no safe or feasible way to directly upload specific values into an ASI ‚ü¶s000015, s000018, s000053 (noted elsewhere in the lecture)‚üß.
This inability to directly instill specific norms or values represents a fundamental challenge in ensuring ASI friendliness ‚ü¶s000027, s000028 (noted elsewhere in the lecture)‚üß.

## üîÑ The Necessity of an Indirect Approach

Given the impossibility of directly uploading specific values into an ASI, an alternative strategy is required to ensure its friendliness ‚ü¶s000017, s000018, s000026 (noted elsewhere in the lecture)‚üß.
Since a "frontal assault" of direct value implantation is not viable, an **indirect approach** is necessary ‚ü¶s000028 (noted elsewhere in the lecture)‚üß.
This indirect method aims to keep human beings "in the loop" regarding value alignment, without requiring them to perform the impossible task of directly uploading specific values ‚ü¶s000052, s000053 (noted elsewhere in the lecture)‚üß.
This shift towards an indirect method is the proposed way to inform the seed computer about what human values might look like, offering a feasible path forward despite the challenges of direct value transfer ‚ü¶s000072, s000073 (noted elsewhere in the lecture)‚üß.