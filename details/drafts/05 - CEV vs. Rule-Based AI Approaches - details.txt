# CEV vs. Rule-Based AI Approaches

This lecture explores the fundamental differences between traditional rule-based approaches in Artificial Intelligence and the concept of Coherent Extrapolated Volition (CEV). It argues that rule-following is an ineffective and problematic method for AI, advocating for CEV as a more tractable and human-aligned way for advanced AI systems to make decisions based on underlying intent rather than rigid rules.

## The Problem with Rule-Based AI

Rule-based AI approaches are considered problematic because *rules are open to interpretation*, leading to *too many different ways of interpreting* them. This makes *rule following virtually impossible* and, in fact, *makes no sense* as it is *not what human beings do*. The core issue with a rule is that an AI might execute it precisely, but the outcome might not be *what was meant* by the rule-setter. Furthermore, rule following is *not open ended*, making systems rigid and prone to misinterpretation. Decades of AI research have shown that *putting human knowledge into systems does not work*, specifically, *putting rules into systems does not work*.

## Understanding Coherent Extrapolated Volition (CEV)

In contrast to rule-based systems, the *volition idea*, or **Coherent Extrapolated Volition (CEV)**, is *not about rule following*. Instead, if a rule exists at all within this framework, it is *one that the computer itself would invent*. The CEV is characterized as *open ended* and *open to interpretation* because it functions as an *abstraction*. Its essence lies in *the thought that counts, the thought behind it*, rather than the literal interpretation of a command. It aims for an AI to do *what I would want you to do if I had all the time in the world to think*, embodying the principle of "do as I mean, not as I say."

## Why CEV is a More Tractable Approach

The lecture posits that implementing CEV is *more tractable* than implementing rules precisely because rules are so prone to misinterpretation. While rule following is not open-ended, CEV is. This open-ended, abstract nature allows an **Artificial Superintelligence (ASI)** to *specifically make decisions in a concrete way* based on the underlying intent. Human beings, when navigating society, do not strictly follow every rule; instead, they act according to *the meaning behind the rule*. The hope is that AI systems, guided by CEV, will similarly understand and act upon this deeper meaning.

## Implications for AI Development

The shift from rule-based systems to approaches like CEV aligns with the discovery that *building general search systems* and *learning systems which are then given data and they go learn for themselves* is what truly works in AI. This suggests that AI should develop its understanding and decision-making capabilities organically rather than being pre-programmed with explicit rules. Modern **Generative AI** is highlighted as an example of technology that is becoming adept at understanding intent, capable of discerning *what the real question was there* behind a user's input, which resonates with the principles of CEV.

## Summary

*   Rule-based AI is problematic because rules are easily misinterpreted, not open-ended, and virtually impossible for AI to follow effectively.
*   Decades of AI research indicate that directly encoding human knowledge or rules into systems does not work.
*   Coherent Extrapolated Volition (CEV) is an alternative approach focused on understanding the underlying intent and abstraction, rather than strict rule following.
*   CEV is considered more tractable because it allows AI to make concrete decisions based on "what was meant," similar to how humans interpret rules.
*   Successful AI development involves building learning systems that derive understanding from data, aligning with CEV's emphasis on intent and self-generated principles.

## Supplement: Key Terms

*   **Coherent Extrapolated Volition (CEV)**: A concept in AI safety, not explicitly defined in the lecture, but described as an abstract, open-ended principle for AI decision-making that focuses on understanding and acting upon the underlying intent or "thought" of its creators, rather than strictly following explicit rules. It aims for the AI to do what its creators *would want* if they had unlimited time to think and refine their desires.
*   **Artificial Superintelligence (ASI)**: A hypothetical AI that would be vastly more intelligent than the best human brains in practically every field, including scientific creativity, general wisdom, and social skills. The lecture mentions an ASI's ability to make concrete decisions based on the abstraction of CEV.