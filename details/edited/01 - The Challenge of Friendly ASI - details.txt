# The Challenge of Friendly ASI

The challenge of Friendly ASI (Artificial Superintelligence) centers on the critical need to ensure that highly advanced artificial intelligence is developed to be trustworthy and safe. This concern emphasizes preventing harm, including human extinction, which is seen as a genuine possibility, primarily through inadvertent actions rather than malicious intent.

## The Urgency of Friendly ASI

Many individuals concerned about the ongoing development of artificial intelligence advocate for immediate attention to ensuring that ASI is *trustworthy* and *safe*. This means addressing the concept of "friendly" ASI right now, as a current and pressing concern.

## Defining "Friendly" ASI

The term "friendly" in the context of ASI does not imply social friendliness. Instead, for those concerned with ASI safety, **friendly ASI** specifically means an intelligence that *will not harm human beings*. A primary concern is that it will *not lead to the extinction of human beings*. This potential for harm is viewed as a genuine possibility, mainly through *inadvertent actions* by the ASI, rather than through deliberate malice, which is considered unlikely.

## Origin of the Term "Friendly AI"

The concept of "friendly AI" was coined by **Eleazar Yudkowski**, who has significantly influenced discussions around the friendliness of AI and ASI. Yudkowski, who did not attend high school or college, is a key figure in raising awareness about these concerns.

## Potential Risks of Unfriendly ASI

Those concerned about the development of ASI see a genuine possibility of harm, including human extinction. This risk is primarily attributed to the ASI's *inadvertent actions*â€”situations where humanity might not fully understand how to interact with or manage the ASI. While malice from an ASI is considered unlikely, the potential for unintended negative consequences is a significant focus.

## Development Context: From Seed AI to Friendly ASI

The concern for friendliness extends to ASI that is developed from "seed AI." As AI systems evolve, there is a continuous need to ensure that the resulting ASI remains friendly, meaning it continues to uphold the principles of trustworthiness and safety for humanity.

## Summary

*   The challenge of Friendly ASI is about ensuring advanced AI is **trustworthy and safe** for humanity.
*   The term "friendly" means the ASI *will not harm human beings*, particularly avoiding human extinction.
*   **Eleazar Yudkowski** coined the term "friendly AI" and is a key figure in this area of concern.
*   The primary risk from unfriendly ASI is seen as arising from *inadvertent actions*, not malice.
*   This concern is urgent and applies to ASI developed from "seed AI," requiring continuous attention to its friendliness.

## Supplement: Explanation of Key Terms

*   **ASI (Artificial Superintelligence):** While not explicitly defined in the lecture, ASI generally refers to a hypothetical intelligence that is vastly smarter than the best human brains in practically every field, including scientific creativity, general wisdom, and social skills. (Supplemental information)
*   **Seed AI:** Also not explicitly defined, "seed AI" typically refers to an AI system designed with the capability to recursively improve itself, potentially leading to the development of ASI. (Supplemental information)