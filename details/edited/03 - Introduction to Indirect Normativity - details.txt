# Introduction to Indirect Normativity

Indirect normativity is presented as an alternative approach to directly uploading values into a seed AI that becomes an Artificial Superintelligence (ASI). It is proposed as a necessary, indirect method when direct attempts to instill specific norms or values are not feasible, aiming to create a trustworthy and safe ASI.

## Definition of Indirect Normativity

**Indirect normativity** is an approach that serves as an alternative to directly uploading values into a *seed AI* that will develop into an *Artificial Superintelligence (ASI)*. It is described as an *indirect* method, necessary when a *direct* or *frontal assault* of instilling specific norms or values is not possible or effective. The lecture emphasizes that this is the core idea of the assigned reading.

## The Need for an Indirect Approach

The lecture highlights that an indirect approach is required because it's not feasible to directly upload specific norms or values into an AI. If a *direct assault* or *frontal assault* on this problem is not possible, then an *indirect* method becomes necessary. This approach aims to overcome challenges encountered previously, which could not be addressed directly.

## Core Purpose and Goals

The primary purpose of indirect normativity is to achieve a *trustworthy and safe* Artificial Superintelligence (ASI). It is considered a *feasible way* to inform the *seed computer* about what *human values* may look like, especially when direct methods of value uploading are insufficient. This method seeks to address problems that could not be solved by direct means.

## Key Characteristics and Origin

Indirect normativity is presented as a *better way to go* compared to the *frontal direct way* of attempting to upload values. The idea for indirect normativity is largely attributed to *Yudkowski*. It represents a shift from direct instruction to a more nuanced, indirect method for guiding AI development.

## Summary

*   **Indirect normativity** is an alternative to directly uploading values into AI.
*   It is necessary when direct methods for instilling specific norms are not feasible.
*   The goal is to create a *trustworthy and safe* Artificial Superintelligence (ASI).
*   It aims to *inform the seed computer about human values* indirectly.
*   This approach is considered a *better* and *feasible* way, with the idea largely stemming from *Yudkowski*.

## Supplement: Understanding Key Terms

*   **Seed AI:** Refers to an initial artificial intelligence system from which a more advanced AI, such as an ASI, is expected to develop or "grow."
*   **ASI (Artificial Superintelligence):** An intelligence that is vastly smarter than the best human brains in practically every field.
*   **Norms/Values:** Principles, standards, or beliefs that are considered important and desirable, which the AI is intended to understand or embody.